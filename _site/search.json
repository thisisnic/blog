[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment\n\n\n\nR\n\nAI\n\n\n\n\n\n\n\n\n\nAug 3, 2025\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nExploring AI-Powered Shiny App Development with Cline and Positron\n\n\n\nR\n\nAI\n\n\n\n\n\n\n\n\n\nMar 17, 2025\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nIterating on an app to create social media posts generating package using {shiny} and {ellmer}\n\n\n\nR\n\nAI\n\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating social media posts to promote blog posts with {shiny} and {ellmer}\n\n\n\nR\n\nAI\n\n\n\n\n\n\n\n\n\nFeb 14, 2025\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nRecurse Center Return Statement\n\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 12, 2024\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nMonitoring R Package Updates with Github Actions\n\n\n\nR\n\nGitHub Actions\n\n\n\n\n\n\n\n\n\nDec 28, 2023\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nExplaining the C bits at the start of ‘Deep R Programming Ch14: Interfacing compiled code’\n\n\n\nR\n\nC\n\n\n\n\n\n\n\n\n\nDec 23, 2023\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nReflections on 2023\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 21, 2023\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nDebugging\n\n\n\nR\n\n\n\n\n\n\n\n\n\nOct 4, 2023\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nThree Goats in a Raincoat\n\n\n\nR\n\n\n\n\n\n\n\n\n\nOct 3, 2023\n\n\nNic Crane\n\n\n\n\n\n\n\n\n\n\n\n\nR package documentation - what makes a good example?\n\n\n\nR\n\nPython\n\n\n\n\n\n\n\n\n\nMay 18, 2021\n\n\nNic Crane\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/debugging/index.html",
    "href": "posts/debugging/index.html",
    "title": "Debugging",
    "section": "",
    "text": "As a package maintainer, I’m constantly disappointed when folks mention Arrow bugs they’re aware of but haven’t reported. Not disappointed with the individual in question, but disappointed with the fact that we’re not at the point where we’ve created an environment in which folks are happy to just report bugs immediately. This is not an Arrow-specific problem, and I find myself behaving in exactly the same way with other open source projects. If I’m not entirely sure something is a bug, I’m not going to risk looking foolish publicly by complaining, but the irony of this is that I don’t judge users who make those mistakes with Arrow, as usually it means we need to improve our docs to be more clear, and that in itself is valuable feedback.\nI really love interacting with people who use the package, as without that interaction, development and maintenance can feel like shouting into the void. I like being able to solve problems that make other people’s lives easier, and I thrive off that social energy. I implemented bindings for dplyr::across() because someone commented on Twitter that they’d love to see it as a feature. Last night I got home from a friend’s birthday drinks, saw a user question on Stack Overflow which had an easy win, and within an hour had a pull request up which implemented a new function and fixed the particular issue. I am not promising this level of responsiveness in perpetuity, but I’m still at the point where I find this kind of thing exciting and energising.\nOne particular bug which has haunted me for the past 6 months, is a particularly irritating one whereby when working with a partitioned CSV dataset in arrow (I’m using lowercase to denote the R package, rather than Arrow the overall project), if the user manually specified a schema, the variable used for partitioning did not appear in the resulting dataset. This is a huge problem IMO - while we can sit here all day talking about the virtues of Parquet, in reality, a lot of our users will be using CSVs, and it’s issues like these that can rule out being able to use arrow at all in some cases.\nWhen I opened the original issue based on another user issue, I knew it was important, but felt a bit stuck. It wasn’t immediately obvious to anyone what the source of the error was. I’d assumed it must be a C++ error and flagged it as such, but nobody had taken a look at it, and I’m always hesitant to mindlessly tag folks on issues when I don’t feel like I’ve done the work to investigate (though to be fair, didn’t really know what “the work” should be in this case).\nI’d ended up assuming that this bit of functionality just didn’t work with CSV datasets, and had been working around it, until I was presenting about arrow at New York Open Statistical Programming Meetup, and someone asked about it again. I take 1 user question as representative of 99 other people with the same issue who aren’t being so vocal about it, and felt like it needed to be fixed. I am unashamed to admit that I occasionally have the taste for a bit of melodrama, and publicly declared it to a few of my fellow contributors as “my white whale”, and so set out to find the source, even if it required me to delve deep into the guts of Arrow’s C++ libraries, a task which can often send me down endless rabbit holes and chasing red herrings (this sentence has become quite the nature park…)\nMy original exploration didn’t result in much useful - the arrow package does some cool things with R6 objects to binding them to Arrow C++ objects, but accessing the inner properties of these bound objects would mean manually creating print methods for every single one of them, and when you don’t know in which class the problem lies, this becomes, frankly, a massive pain in the arse. I still didn’t have enough to go on to take it to an Arrow C++ contributor and ask for their help, but showing I’d done some of “the work” to at least make an effort myself.\nAnd then collaborative debugging saved me! I had a catchup with the fantastic Dane Pitkin, and I asked for his help just walking through the problem. Dane’s main contributions to Arrow have been to Python, though he has a ton of previous C++ experience, even if he isn’t a regular contributor to the Arrow C++ library. I walked through the problem with him, and the steps I’d taken so far to try to figure things out, and the fact that I still needed to figure out if the problem was in R or C++. Dane commented that the object bindings we’d been looking at had little surface area for the problem to be in R - most of them were straight-up mappings from the C++ object to an R6 object with no extension. This was my first big clue! I remembered that there’s a bit of open_dataset() where we do some manual reconfiguration of specified options, which involves a whole load of R code - something I’ll come back to later. Dane also suggested I check out Stack Overflow to see if people were complaining about the issue in C++ there. I was sceptical that I’d find anything - lots of these bugs are more often surfaced in the R and Python libraries - but realised that this wasn’t the dead end that I’d thought. It suddenly occurred to me that if I could reproduce the bug in PyArrow, then the problem must lie in the C++ library, but if I couldn’t, then the problem lay in the R code.\nFifteen minutes later, and I had confirmed it was an R problem. I happened to mention on Slack the problem I was having, steps I’d taken so far to investigate, and potential ideas to look at next, and ended up engaging in a bit more collaborative debugging, this time with the wonderful Dewey Dunnington, who mentioned more disparities between PyArrow and R in terms of how we construct schemas, which put me on the path of testing the schema values at different points in Dataset creation and able to rule that out. At that point, with a smaller problem space to explore, the only logical thing left to look into was the R code which sets up the options for the various Arrow classes, and I ended up spotting the rogue instantiation of CSVReadOptions which just needed to have the partitioning column excluded (it relates to the reading in of the individual files which make up the dataset, and so has no “knowledge” of the partitions, and so previously raised an error as it treated them as an extraneous column).\nOne pull request later, and the problem that I’d given myself a week to look at had been solved in less than a day! This is probably one of the most gratifying bugs I’d worked on all year; there was a user with a problem to solve, a bug which had been annoying me for ages, the chance to fall into the puzzle-like aspects of debugging, and some great opportunities for collaboration with folks whose help here I really appreciated. This is one of the things I enjoy most about being a software engineer; this process of starting off feeling entirely clueless about something, and having to work out where I need to be and how I’m going to get there, and then doing it. Actually, in the abstract, that’s probably one of the things I enjoy most about being a human :)"
  },
  {
    "objectID": "posts/2023wrapup/index.html",
    "href": "posts/2023wrapup/index.html",
    "title": "Reflections on 2023",
    "section": "",
    "text": "Here’s a summary of my highlights of 2023!"
  },
  {
    "objectID": "posts/2023wrapup/index.html#arrow-positconf-workshop",
    "href": "posts/2023wrapup/index.html#arrow-positconf-workshop",
    "title": "Reflections on 2023",
    "section": "Arrow posit::conf workshop",
    "text": "Arrow posit::conf workshop\nThe biggest professional achievement for me was having the privilege of being invited to co-present a workshop with Steph Hazlitt about Arrow at posit::conf. Steph is fantastic to work with, and while writing and delivering the workshop was hard work, it paid off in the end - we received really positive feedback from attendees. The experience reignited my passion for teaching, and desire to develop those skills. I’ve applied for Carpentries instructor training, which I’m still waiting to hear back about, and I’m excited to also be working with Steph on creating a 2 hour version of the workshop, which we’re planning on teaching at user events in 2024.\n\n\n\nHanging out with some awesome people at posit::conf 2023!"
  },
  {
    "objectID": "posts/2023wrapup/index.html#arrow-r-maintenance-bot",
    "href": "posts/2023wrapup/index.html#arrow-r-maintenance-bot",
    "title": "Reflections on 2023",
    "section": "Arrow R Maintenance bot",
    "text": "Arrow R Maintenance bot\nAnother project I enjoyed working on was creating the Arrow maintenance bot. It pulls data from the GitHub API, aggregates the relevant bits, and then posts it to a Zulip channel (though also works for Slack). It was an itch I’d wanted to scratch for a long time, as I’d previously got this information by clicking on various bookmarks every so often whenever I remembered. The output is shown in the screenshot below; basically, it summarises new bug tickets which need investigating, investigated bugs which need a fix, and open PRs which may need reviewing. \nThere are more aspects of arrow maintenance which I’d love to automate and pull together in dashboard form - I’ve been discussing this with a friend, and I hope we find the time to work on this in 2024!"
  },
  {
    "objectID": "posts/2023wrapup/index.html#arrow-maintenance-and-book",
    "href": "posts/2023wrapup/index.html#arrow-maintenance-and-book",
    "title": "Reflections on 2023",
    "section": "Arrow maintenance and book",
    "text": "Arrow maintenance and book\nIn January, I became the official package maintainer on CRAN. It took my some time to get my head around this; it’s a daunting responsibility, and in reality I’m part of a wider team, all of whom play an important part.\nThe amount of time I’ve been able to spend on Arrow has dropped significantly since I left Voltron Data, though I’m hoping to be able to spend more time this year on it. I feel like my focus will shift a little, away from code, and more towards encouraging new contributors, as well as teaching people how to use the package.\nMost excitingly though, is the book which I am co-authoring! This is taking up the main chunk of my Arrow-related time, but the aim is to have the manuscript submitted to the publishers by summer, if not sooner."
  },
  {
    "objectID": "posts/2023wrapup/index.html#c",
    "href": "posts/2023wrapup/index.html#c",
    "title": "Reflections on 2023",
    "section": "C++",
    "text": "C++\nHaving interacted with bits of C++ code while working on Arrow, I decided to spend time learning C++ more formally. I’ve generally found this tricky - frankly, higher-level languages seem to have more engaging content out there. I made a start on the Udacity C++ Nanodegree, which I completed over half of, but was limited on time and so paused this - I plan to pick it up again next year though. I also tried a more practical approach, and decided to make a PR to the Arrow C++ codebase - one of the PRs I am most proud of this year is this one, adding support for the Substrait cast expression. It was hard, though most of the complexity came from peripheral tasks, like working out how to run the code interactively in the debugger."
  },
  {
    "objectID": "posts/2023wrapup/index.html#joining-the-rladies-global-team",
    "href": "posts/2023wrapup/index.html#joining-the-rladies-global-team",
    "title": "Reflections on 2023",
    "section": "Joining the RLadies Global team",
    "text": "Joining the RLadies Global team\nI spent some time thinking about how I could engage more with the wider R community, and so I volunteered to join the RLadies global team, helping set up new chapters on meetup.com. I’ve not done much here yet, but am delighted to be part of the organisation, and hope to be able to help out more in 2024"
  },
  {
    "objectID": "posts/2023wrapup/index.html#career-break-and-plans-for-2024-recurse-center",
    "href": "posts/2023wrapup/index.html#career-break-and-plans-for-2024-recurse-center",
    "title": "Reflections on 2023",
    "section": "Career break and plans for 2024 (Recurse Center!)",
    "text": "Career break and plans for 2024 (Recurse Center!)\nLast, but absolutely not least, is my decision to take a career break. After leaving Voltron Data, I’d been working part-time in a contractor capacity, alongside working on the Arrow book, but I decided I wanted to narrow my focus and take some time out for me.\nI’m taking a break and spending the next couple of months focusing on writing. Once most of the book is done, I plan to spend more time on my open source work in general, which will involve teaching and talking about Arrow, as well as pushing forward a few side projects.\nThe most exciting news I’ve had this year is that I applied to the Recurse Center a few weeks ago. RC is like a writer’s retreat for programmers, and attendees spend 12 weeks together working on programming problems of their choice. I want to get to grips with R’s internals, and learn about the C API, as well as levelling up my C++ skills in general. I’m delighted to say that I was accepted to attend this morning, and will be joining the spring batch in late March! I’ve got a ton of ideas for projects I want to work on, but will have to see how much time I ultimately end up having.\nLonger-term - I don’t know. Ultimately, I’d love to get paid to work on open source again, but those opportunities are few and far between. I also have some professional goals I’d like to hit before I’m going to be in the right headspace to engage with this too - between writing the book and my plans for Recurse Center, I’ll be there pretty soon.\nThis year has been a real rollercoaster, but I’m extremely grateful to all my friends and mentors who have helped me during this time."
  },
  {
    "objectID": "posts/clineshiny/index.html",
    "href": "posts/clineshiny/index.html",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "",
    "text": "As a fun bit of prep for Appsilon’s upcoming AI-Powered Shiny Hackathon on March 22, 2025, I decided to do a practice run using Cline, an AI coding assistant. My goal was to see how AI can help or hinder the development of a Shiny application.\nI decided to see where I could get in an hour today, and this blog post discusses my experience, highlighting the capabilities, quirks, and costs of using AI for R and Shiny app development."
  },
  {
    "objectID": "posts/clineshiny/index.html#the-hackathon-challenge",
    "href": "posts/clineshiny/index.html#the-hackathon-challenge",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "📌 The Hackathon Challenge",
    "text": "📌 The Hackathon Challenge\nThe hackathon is judged on:\n\nHow well the app meets the challenge objectives\nAdditional features built\nUI design and user experience\nCode clarity and maintainability\n\nThe details of the hackathon will be revealed on the day, so I decided to try to come up with a small task which may have some things in common - creating a Shiny app which visualises and analyses a dataset."
  },
  {
    "objectID": "posts/clineshiny/index.html#data-acquisition-nyc-open-data",
    "href": "posts/clineshiny/index.html#data-acquisition-nyc-open-data",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "📂 Data Acquisition: NYC Open Data",
    "text": "📂 Data Acquisition: NYC Open Data\nI decided to take a look at NYC Open Data and within that, my partner and I agreed that the restaurant health inspection dataset looks the most interesting.\nNYC Open Data provides APIs and browser-based tools for exploring datasets. Instead of using APIs, I opted to download the datasets manually for simplicity.\n\nInspection Results Dataset (120MB CSV)\nData Dictionary (Excel file)\nAdditional Documentation (Word file)\n\nAt this point, I didn’t check the documentation—I wanted to see how much Cline could figure out on its own."
  },
  {
    "objectID": "posts/clineshiny/index.html#enter-cline-ai-coding-assistant",
    "href": "posts/clineshiny/index.html#enter-cline-ai-coding-assistant",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "🛠️ Enter Cline: AI Coding Assistant",
    "text": "🛠️ Enter Cline: AI Coding Assistant\nCline is an AI-powered coding tool that integrates into VS Code and Positron. It autonomously creates and edits files, executes commands, and interacts with code, all while asking for user approval at each step.\n\n🔹 Key Features of Cline:\n\nPlan Mode: Outlines a roadmap before execution\nAct Mode: Runs code when switched to execution mode\nTransparent Cost Tracking: Displays API usage and expenses\n\nI started with a broad prompt:\n\n‘Using all of the resources in the data directory, take a look at the data, and come up with some ideas for interesting analyses, such as “which restaurants have the worst health scores but remain very popular” - focus on what is available in the data and what is unexpected and humorous’\n\nCline responded by:\n\nListing the available files and guessing their contents\nAsking for permission to read each file\nSuccessfully reading the Word doc\nTrying (and failing) to read the Excel file\n\n\n\n\nCline File Summary"
  },
  {
    "objectID": "posts/clineshiny/index.html#data-exploration-and-analysis",
    "href": "posts/clineshiny/index.html#data-exploration-and-analysis",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "🔍 Data Exploration and Analysis",
    "text": "🔍 Data Exploration and Analysis\nCline wanted to open the full 120MB dataset but since the file was large, my partner mentioned that there might be costs associated with sending data to the AI. I mentioned this to Cline, and so it opted instead to sample the first few rows.\nAfter some failed attempts with PowerShell, I nudged it toward using R instead, which worked much better.\n\n\n\nPowerShell Issue\n\n\nI really like how the responses are in a human-readable format while planning actions to take, so that I could see the equivalent of its line of thought. It had proposed analyses such as:\n\nIdentifying popular restaurants with poor health scores\nAnalysing violation trends across neighborhoods\nExamining seasonal variations in health violations\n\nSome ideas sounded interesting, but others were a bit off. This reflected the trend I’d seen in chatGPT where unless prompted to do otherwise, a large number of ideas are returned; some more useful than others.\nI pressed it on some of them, at which point it was able to propose alternatives. There was still a great deal of input needed from me to decide which idea would be the most sensible to go with.\n\n\n\nInspection Proxy Popularity Question"
  },
  {
    "objectID": "posts/clineshiny/index.html#building-the-shiny-app",
    "href": "posts/clineshiny/index.html#building-the-shiny-app",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "🎨 Building the Shiny App",
    "text": "🎨 Building the Shiny App\nWith the analysis ideas outlined, I instructed Cline to build a Shiny app to visualise the insights.\n\n\n\nInitial R Code Approach\n\n\n\n🔹 What Cline Generated:\n\nA UI with slider inputs\nBar charts using the viridis color palette\nIcons for different metrics\n\nIssue #1:\n\nCline overused Plotly, adding unnecessary complexity.\nI switched most plots back to ggplot2 for clarity.\n\nIssue #2:\n\nSome colors were misleading—viridis was applied without meaning, making bars look color-coded incorrectly.\n\nIssue #3:\nThe app was all in one huge file - so I asked Cline to make it more modular, again, remaining vague to see what it did."
  },
  {
    "objectID": "posts/clineshiny/index.html#the-app-itself",
    "href": "posts/clineshiny/index.html#the-app-itself",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "📊 The App Itself",
    "text": "📊 The App Itself\nThe main page of the app itself can be seen below. It looks pretty decent, right?\n Except for that it kinda wasn’t! This overview page was fine, but the individual subpages were suffering from all sorts of issues, from truncated output in DT outputs, to it being unclear what some plots were trying to show. With some time and effort I could have unpicked it, but at this point I was wondering if it would have been quicker to code from scratch."
  },
  {
    "objectID": "posts/clineshiny/index.html#refactoring-and-modularisation",
    "href": "posts/clineshiny/index.html#refactoring-and-modularisation",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "🏗️ Refactoring and Modularisation",
    "text": "🏗️ Refactoring and Modularisation\nAt this point Cline split the app into ui.R, server.R and a few other supporting files, though not as modular as I’d have liked. I tried again, this time seeing if it would use the {golem} framework - with much more success.\nCline successfully:\n✅ Created a new Golem project directory\n✅ Structured the app as an R package\n✅ Included a DESCRIPTION file\nHowever, I had to manually fix some file paths to make everything work.\n\n\n\nRefactoring with Golem"
  },
  {
    "objectID": "posts/clineshiny/index.html#the-cost-of-ai-assistance",
    "href": "posts/clineshiny/index.html#the-cost-of-ai-assistance",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "💰 The Cost of AI Assistance",
    "text": "💰 The Cost of AI Assistance\nCline provides a breakdown of API costs per request. After one hour of work, I had spent:\n💰 $3 total\nInterestingly, some human-like responses cost more than code generation! For example, a single conceptual AI response cost $0.17, more than some entire code snippets.\n\n\n\nCost Breakdown"
  },
  {
    "objectID": "posts/clineshiny/index.html#final-thoughts-ais-role-in-shiny-development",
    "href": "posts/clineshiny/index.html#final-thoughts-ais-role-in-shiny-development",
    "title": "Exploring AI-Powered Shiny App Development with Cline and Positron",
    "section": "🏁 Final Thoughts: AI’s Role in Shiny Development",
    "text": "🏁 Final Thoughts: AI’s Role in Shiny Development\nThis experiment showed me a few important things:\n\nVague prompts get mixed results\nAI is better at writing code than about making decisions about data science and how best to represent data\nCosts can add up quickly and being strategic about which aspects to use Cline for feels like the best way forward\n\nThis made me really reflect on the role of AI here. On an app development team, would you rather have 1 person who does it all, or a team of people with different specialisations? I think the latter would work better, for the hackathon itself, I’m going to experiment with a few different approaches such as:\n\nSetting up the app structure myself in advance, and getting Cline to fill in the gaps based on what’s already there\nGPT product manager - putting together a prompt around constructing really well-defined requirements, and using that to help me tightly define what is being created before passing those requirements onto an AI like Cline to create them\ndesigning any plots myself - there may be ways to improve on what was generated here today, but representing data in a human-understandable form might just be best done by humans\n\nI’m looking forward to Saturday’s hackathon - good luck to everyone else participating and I’m super excited to see what comes out of it! 🚀"
  },
  {
    "objectID": "posts/socalmediagen2/index.html",
    "href": "posts/socalmediagen2/index.html",
    "title": "Iterating on an app to create social media posts generating package using {shiny} and {ellmer}",
    "section": "",
    "text": "I recently posted about a repo I created containing a Shiny app which allows users to generate social media posts to promote blog posts, using {shiny} and {ellmer}.\nIf you haven’t used it before, {ellmer} is an R package which allows you to call LLMs directly from R.\nI’ll admit right now that, although I’d already been using the LLM prompt used in that project for a while, I threw together the app and associated code in a couple of hours to give me something to write about. People seemed receptive to the blog post, but I wasn’t happy with the code, and so I decided to tidy it up a bit.\nIn this post, I’m going to discuss the changes I made to get from a few messy scripts to a deployable R package that is much easier to maintain."
  },
  {
    "objectID": "posts/socalmediagen2/index.html#step-1-convert-the-scripts-into-an-r-package",
    "href": "posts/socalmediagen2/index.html#step-1-convert-the-scripts-into-an-r-package",
    "title": "Iterating on an app to create social media posts generating package using {shiny} and {ellmer}",
    "section": "Step 1: Convert the scripts into an R package",
    "text": "Step 1: Convert the scripts into an R package\nI’m a big fan of writing code as R packages wherever possible; it provides instant structure and reminds me to do important fundamentals such as documenting functions, and writing modular pieces instead of long scripts.\nI moved the app code into ./R/app.R and separated out the other functions into a file ./R/prompts.R.\nI also moved the CSS for the app into the package’s inst dir and created a subdirectory in inst to store my prompts.\n\n\n\nContents of the inst dir"
  },
  {
    "objectID": "posts/socalmediagen2/index.html#step-2-saving-the-prompts-in-their-own-file",
    "href": "posts/socalmediagen2/index.html#step-2-saving-the-prompts-in-their-own-file",
    "title": "Iterating on an app to create social media posts generating package using {shiny} and {ellmer}",
    "section": "Step 2: Saving the prompts in their own file",
    "text": "Step 2: Saving the prompts in their own file\nNext, was where to save the prompts. Originally these were saved as variables, but in the ellmer vignette on prompt design, it’s recommended that these are saved in ./inst/prompts/ with one file per prompt.\nThe ellmer vignette recommends saving prompts as markdown files as they’re both human-readable and LLM-readable, and so I saved my main prompt as shown below:\nCreate me social media posts for each of these platforms: {{platforms}}, to promote the blog post below.\n\n* create {{n}} posts per platform\n* use a {{tone}} tone\n* use hashtags: {{hashtags}}\n* use emojis? {{emojis}}\n\n# Blog post contents\n\n{{post_contents}}\nYou’ll notice the use of placeholders in the prompt. This is because {ellmer} has a helpful function which can read the prompt and inject in variable values. So the last line of my get_prompt() function looks like this:\nellmer::interpolate_file(\n    system.file(\"prompts\", \"prompt-main.md\", package = \"socialmediagen\"),\n    platforms = paste(platforms, collapse = \", \"),\n    n = n,\n    tone = tone,\n    hashtags = hashtags,\n    emojis = emojis,\n    post_contents = post_contents\n)"
  },
  {
    "objectID": "posts/socalmediagen2/index.html#step-3-creating-platform-specific-prompts",
    "href": "posts/socalmediagen2/index.html#step-3-creating-platform-specific-prompts",
    "title": "Iterating on an app to create social media posts generating package using {shiny} and {ellmer}",
    "section": "Step 3: Creating platform-specific prompts",
    "text": "Step 3: Creating platform-specific prompts\nI realised that best-practices for social media posts vary from platform to platform, and I wanted to experiment with having different prompts depending on which platforms were selected by the user.\nI first added the following to my main prompt:\n# Platform-specific advice\n\nUse the following advice to customise the output for individual platforms:\n\n{{platform_specific_advice}}\nI then created additional prompts tailored to each platform, for example, my LinkedIn prompt looks like this:\nLinkedIn:\n* Keep posts between 1,300 and 2,000 characters. \n* Use short sentences: Posts with sentences under 12 words perform better. \n* ask questions: Encourage comments by asking questions that prompt discussion. \n* give specific instructions: Ask readers to like your post or take another action. \n* use a compelling headline: Grab attention with your first line. \n* use 3 hashtags\nI then saved all of these into the inst/prompts directory.\n\n\n\nContents of the prompt dir\n\n\nI then created a super-simple function to retrieve the relevant prompt:\n#' Retrieve post-writing advice unique to specific platforms\n#'\n#' @param platforms Which platforms to get advice for\nget_platform_specific_advice &lt;- function(platforms){\n  prompt_files &lt;- paste0(\"prompt-\", tolower(platforms), \".md\")\n  file_paths &lt;- system.file(\"prompts\", prompt_files, package = \"socialmediagen\")\n\n  contents &lt;- lapply(file_paths, readLines)\n  paste(unlist(contents), collapse = \"\\n\")\n}\nFinally, I updated my get_prompt() function to incorporate these changes:\n#' Construct LLM prompt\n#'\n#' Construct a LLM prompt based on user input\n#'\n#' @param blog_link URL of source material\n#' @param platforms Social media platform to create prompts for\n#' @param n Number of prompts to create for each platform\n#' @param emojis Use emojis in post?\n#' @param tone Desired tone of the post\n#' @param hashtags Hashtags to include in the post\n#' @importFrom ellmer interpolate_file\nget_prompt &lt;- function(blog_link, platforms, n, emojis, tone, hashtags) {\n  # retrieve post contents from GitHub\n  post_contents &lt;- fetch_github_markdown(blog_link)\n\n  platform_specific_advice &lt;- get_platform_specific_advice(platforms)\n\n  # combine components\n  ellmer::interpolate_file(\n    system.file(\"prompts\", \"prompt-main.md\", package = \"socialmediagen\"),\n    platforms = paste(platforms, collapse = \", \"),\n    n = n,\n    tone = tone,\n    hashtags = hashtags,\n    emojis = emojis,\n    post_contents = post_contents,\n    platform_specific_advice = platform_specific_advice\n  )\n}"
  },
  {
    "objectID": "posts/socalmediagen2/index.html#the-resulting-app",
    "href": "posts/socalmediagen2/index.html#the-resulting-app",
    "title": "Iterating on an app to create social media posts generating package using {shiny} and {ellmer}",
    "section": "The resulting app",
    "text": "The resulting app\nMy app now is able to create platform-specific content and is much better organised than it was before. I think that updating the prompt was useful - check out the example below of the content generated before and after. The LinkedIn post now it has a strong call-to-action and asks the user a question.\n\nBefore\n\n📢 Calling all data enthusiasts! 📢\n\nThinking about speaking at Posit Conf 2025 but feeling a bit 😬 about the video abstract? Don't sweat it! This year the abstract just needs to be a short video!\n\nWe've compiled some top tips from past speakers to help you nail that one-minute pitch! 🚀\n\n➡️ Learn how to structure your video, what tech to use, and how to inject some of YOUR personality into it! (Humor and creativity are welcome!)\n\nPlus, we're offering feedback on drafts! 📝\n\n[Link to Blog Post]\n\n#rstats\n\n\nAfter\n\n**Headline:** Nervous About Your Posit Conf Video Abstract? 😩 Don't Be!\n\nThinking of speaking at #PositConf2025 but dreading the video abstract? You're not alone! It's just one minute to shine ✨.\n\nWe've got tips from past speakers Rachael Dempsey, Shannon Pileggi, and Nic Crane to help you nail it! From tech options (easy peasy phone cam to fancy OBS Studio) to structuring your pitch, we've got you covered.\n\n**Blog Post Highlights:**\n\n*   Simple tech options\n*   Easy structure for your video\n*   How to get feedback\n\nReady to record? Check out our tips and let your brilliance shine. 💡\n[Link to blog post]\n\nWhat's your biggest video recording fear? Share in the comments! 👇\n\n#rstats #rladies #positconf"
  },
  {
    "objectID": "posts/socalmediagen2/index.html#reflecting-on-llm-based-apps",
    "href": "posts/socalmediagen2/index.html#reflecting-on-llm-based-apps",
    "title": "Iterating on an app to create social media posts generating package using {shiny} and {ellmer}",
    "section": "Reflecting on LLM-based apps",
    "text": "Reflecting on LLM-based apps\nI enjoyed building this example, and on some levels, it doesn’t do anything particularly radical. The same results could be achieved by using the same prompts in a browser session and manually filling in the parameters. However, what I do like about this is that I have a specific place to store my prompts - in a GitHub repo - where I can iterate on them and track changes over time.\nI also like that I now have a deployable artifact that I can share with others - I had mentioned to other members of the R-Ladies Global Team that I had been using LLMs to generate social media posts for promoting our news and blog posts, and this means I can easily share the link to the repo with the app, instead of having to share a prompt. Creating this as a distinct project encourages collaboration, whether that’s on which parameters we want to include in the app, or improving the quality of the prompts."
  },
  {
    "objectID": "posts/llms_for_learning/index.html",
    "href": "posts/llms_for_learning/index.html",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "",
    "text": "There’s a lot of advice out there at the moment about using LLMs for code generation, but something I’ve been curious about is using LLMs for learning around code.\nIn this blog post I’m going to talk about using an LLM, specifically, ChatGPT to extend my own knowledge in R."
  },
  {
    "objectID": "posts/llms_for_learning/index.html#context---adding-a-feature-to-daisyuiwidget",
    "href": "posts/llms_for_learning/index.html#context---adding-a-feature-to-daisyuiwidget",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "Context - adding a feature to daisyuiwidget",
    "text": "Context - adding a feature to daisyuiwidget\nI’m currently collaborating with Charlotte Hadley on an R package called daisyuiwidget. It an htmlwidgets package.\n\nhtmlwidgets\nCharlie and I both really lovely htmlwidgets packages which are used to wrap JavaScript libraries and work with them from R. They can be used in HTML outputs like Quarto documents and Shiny apps.\nOne example of a htmlwidgets package is DT, which can be used to create interactive tables. You can see an example below.\n\nlibrary(DT)\n\npackages &lt;- data.frame(\n    package = c(\"htmlwidgets\", \"leaflet\", \"plotly\", \"DT\"),\n    first_release = as.Date(c(\"2014-12-09\", \"2015-06-24\", \"2015-11-17\", \"2015-06-09\")\n    )\n)\n\nDT::datatable(packages)\n\n\n\n\n\nOne of the excellent features about packages like DT is that they can go beyond just displaying outputs. If you include a DT table in a Shiny app and have enabled “row selection”, then the JavaScript code for the table can pass the index of the user’s selected row back to R. This then can be used in other components of the app, for example, displaying information relevant to the user’s selection.\n\n\ndaisyuiwidget\nThe goal with daisyuiwidget is to create a new htmlwidgets package, using LLMs - we’ll be talking more about this in our joint presentation at Shiny in Production later on this year.\nWe decided to create a wrapper for the daisyUI library which has a feature where it can be used to create timelines like the one below.\n\n\n\n\n\nThe project was at the point where the package successfully created a timeline from a data.frame input. The next task for me to do was implement the functionality for timeline event selection, with the goal that when a user clicks on an event in the timeline, an input variable in R is updated, which then can be hooked up to other bits of Shiny reactivity.\nThis is what I’ll be discussing below - how I got ChatGPT to help with this, but with helping me learn how to do it myself, and not just getting the LLM to write the code."
  },
  {
    "objectID": "posts/llms_for_learning/index.html#aside---the-stretch-zone",
    "href": "posts/llms_for_learning/index.html#aside---the-stretch-zone",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "Aside - the stretch zone",
    "text": "Aside - the stretch zone\nI’m going to be talking at Posit Conf about increasing productivity with LLMs and a central part of my talk is the idea that LLMs are most useful when working on tasks just outside of your comfort zone, sometimes described as your stretch zone.\nI’m defining the “stretch zone” in this context as something that isn’t within your current knowledge, but doesn’t seem so challenging that you have doubts about whether you can find a solution.\nThis task seemed like a great fit for this in terms of my past experience:\n✅ Extensive Shiny app development experience\n✅ Experience using row selection in DT-based apps to update other components\n✅ Some JavaScript experience\n❌ Very limited experience of how to implement htmlwidgets package from scratch\n❌ Never implemented Shiny reactivity for UI components before"
  },
  {
    "objectID": "posts/llms_for_learning/index.html#learning-with-llms",
    "href": "posts/llms_for_learning/index.html#learning-with-llms",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "Learning with LLMs",
    "text": "Learning with LLMs\nI’d been reading a paper by Dr Xi Lin about the idea of using LLMs in self-directed learning.\n\nLin, X. (2023). Exploring the Role of ChatGPT as a Facilitator for Motivating Self-Directed Learning Among Adult Learners. Adult Learning, https://doi.org/10.1177/10451595231184928\n\nDr Lin discusses a self-directed learning framework proposed by Kim et al (2014) with the following aspects:\n\nEstablishing Learning Goals\nLocate and Access Resources\nAdopt and Execute Learning Activities\nMonitor and Evaluate Performance\nReassess Learning Strategies\n\nThis framework can be used with ChatGPT to help support adult learners, and Dr Lin goes on to walk through a hypothetical example where an adult learner is using ChatGPT in each of those steps and discusses the kind of help that could be given.\nI wanted to try some of this out, and so I created summaries of each of the steps along with Dr Lin’s suggestions of how an LLM might implement them, and used them as prompts in a learning session with ChatGPT. I focused solely on steps 1 to 3 as the learning goal was an individual task rather than an ongoing programme."
  },
  {
    "objectID": "posts/llms_for_learning/index.html#step-1---establish-learning-goals",
    "href": "posts/llms_for_learning/index.html#step-1---establish-learning-goals",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "Step 1 - Establish Learning Goals",
    "text": "Step 1 - Establish Learning Goals\nDuration: 7 minutes\nI wrote a little context about what I was trying to achieve, and pasted that and my summary of step 1, into ChatGPT.\nChatGPT asked me five questions:\n\nwhat my goals were\nmy past experience\nexactly what it was that I was trying to achieve\nmy preferred end state\nhow long I wanted to spend working on this\n\nIt took my answers and generated a primary learning goal with supporting objectives.\n\nPrimary Learning Goal:\nWithin the next few hours, I want to understand and implement the necessary code to make my existing htmlwidget timeline respond to user interaction in a Shiny app—specifically, capturing a selected event and updating a variable on the server side.\nSupporting Objectives:\n\nIdentify how event selection can be captured in JavaScript and passed to Shiny via Shiny.setInputValue().\nModify the widget’s JS code to emit a Shiny input when a user selects an event.\nTest and verify that the input value is received in Shiny and reflects the expected event ID or index.\nWrite a minimal working Shiny app that uses the widget and displays the selected event value.\n\n\nI feel that the value I got here from incorporating ChatGPT was clarity. The resulting learning goal was more precise than my original stated aim, and the supporting objectives made for concrete steps to aim for in pursuit of the overall goal.\n\n\n\n\n\n\nExpand to view full conversation\n\n\n\n\n\n\nI am looking at how I can get LLMs to help me with a coding task as an intelligent tutor and not just solve the problem for me. My first step is establishing a learning goal or goals. Using the brief below, ask me questions one at a time to help me work out a small set of goals in this exercise.\nEstablish learning goals\nWhen establishing goals for self-directed learning, it’s most important for learners to set SMART goals: Specific, Measurable, Achievable, Relevant, and Time-bound. This approach helps adult learners identify clear learning objectives and stay focused on achieving them.\nGoals should be personalized and align with the learner’s interests, motivations, and expected learning outcomes. It’s crucial to break down broader objectives into smaller, manageable tasks to make them more achievable.\nAdditionally, learners should consider how their goals relate to their personal and professional contexts, ensuring relevance. Setting a realistic timeline for accomplishing these goals is also essential.\nWhile learners can use tools like ChatGPT to assist in goal-setting, it’s important to remember that the quality of recommendations depends on the information provided by the learner. Therefore, clear communication of interests, motivations, and expectations is crucial when using such tools.\n\n\nLet’s start by grounding this in why you’re doing it.\nQuestion 1: What’s your motivation for using LLMs as a tutor rather than a problem-solver—what do you hope to gain from this approach (e.g., deeper understanding, confidence, skill retention, etc.)?\n\n\nI want to understand how I can take an R package which creates a htmlwidget and adds the correct code so that I can use it in a shiny app and update a variable based on what the user has selected. I want to learn how to do this as I think it’s a useful skill to have. I don’t want an LLM to do it as I won’t know if the code is correct or not and would only have surface level understanding and so would be hard ti repeat the skill in future.\n\n\nQuestion 2:\nWhere are you starting from? For example:\n\nHave you ever written your own htmlwidget package from scratch\nDo you already have a specific widget/package in mind?\nHave you previously connected any JS-based input to Shiny reactivity?\n\n(Just answer what’s true for you—this is to calibrate the scope of your learning goal.)\n\n\nI have never written an htmlwidget package from scratch although I do have one I’ve written with an LLM that I’d like to add this functionality to. It creates the widget but doesn’t have the shiny functionality yet. I’ve not done much of this connectivity before, though have worked with packages that implement it themselves.\n\n\nThat gives us a baseline. You’ve got a partial htmlwidget and prior exposure to packages that do this right, but you haven’t yet wired up JS-to-R reactivity yourself.\nQuestion 3:\nWhat exactly do you want the user to select in your widget, and what kind of R-side variable or behavior do you want to update in response? (Try to be concrete—e.g., “user clicks on a bar in a chart, I want to update a reactiveVal() in the server with the bar’s label.”)\n\n\nSo the widget display a timeline of events and I want the user to select an event, and some variable updates. I’ve seen similar functionality in the DT package where the user clicks on a row in a table, and some variable tracks which row is selected and the data from that row. I can’t remember exactly what data it tracks, it could just be the row number and then the user can write a function to extract the data from an underlying data.frame; this is fine too.\n\n\nPerfect—this is concrete enough.\nYou want to let the user select an event from a timeline displayed via your htmlwidget, and capture that selection in the Shiny server logic—ideally as an index or ID you can work with to retrieve more data.\nQuestion 4:\nWhat’s your ideal end state for this learning exercise? For example:\n\nDo you want to be able to reproduce this pattern in other widgets you make?\nAre you aiming to read or modify similar functionality in other packages?\nOr is this just about getting this one widget working?\n\n\n\nIt’s about getting this one working, although I would like to be able to do it again if I ever make another htmlwidgets package.\n\n\nGot it. So the primary goal is getting this specific widget working, and a secondary goal is gaining enough understanding to repeat the pattern if needed.\nQuestion 5:\nWhat’s your time horizon? Do you want to finish this within a day, a week, or are you treating it as an open-ended background task?\n\n\nI’d like to finish this within a few hours and not overcomplicate it\n\n\nGood. A short, focused goal with an emphasis on practical understanding.\nHere’s a draft of your SMART-aligned learning goals based on what you’ve said:\n\nPrimary Learning Goal:\nWithin the next few hours, I want to understand and implement the necessary code to make my existing htmlwidget timeline respond to user interaction in a Shiny app—specifically, capturing a selected event and updating a variable on the server side.\nSupporting Objectives:\n\nIdentify how event selection can be captured in JavaScript and passed to Shiny via Shiny.setInputValue().\nModify the widget’s JS code to emit a Shiny input when a user selects an event.\nTest and verify that the input value is received in Shiny and reflects the expected event ID or index.\nWrite a minimal working Shiny app that uses the widget and displays the selected event value.\n\n\nDo you want to adjust or narrow any part of that before we move to designing how the LLM will help you stay in tutor mode for this?"
  },
  {
    "objectID": "posts/llms_for_learning/index.html#step-2---locate-and-access-resources",
    "href": "posts/llms_for_learning/index.html#step-2---locate-and-access-resources",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "Step 2 - Locate and Access Resources",
    "text": "Step 2 - Locate and Access Resources\nDuration: 11 minutes\nThe second stage was identifying resources for learning.\nIt started smoothly - ChatGPT asked me if I preferred to learn by reading, watching, or doing, and when I replied “doing” it assured me that it would find code-first resources with working examples - great!\nIt gave me some options about kinds of examples I was interested in, and asked which htmlwidgets packages I was more familiar with so we could use those as examples to look at. At this point it suggested some initial links, but 2 out of the 3 didn’t actually work.\nWhen I complained about this, it gave me some code examples to try out, which I pushed back on, stating I wanted resources to learn from and not ChatGPT-generated code,\nAt this point, it gave me a list of resources, divided into categories and a summary of what it had provided. The links supplied here did all work this time, but there was too much information, and a real risk of overwhelm.\nI began to skim through a few articles, before I remembered that the aim of this step was only to identify resources, and not to deep dive into them quite yet, and so instead I moved onto the next step.\n\n\n\n\n\n\nExpand to view full conversation\n\n\n\n\n\n\nNow the next thing I need to do it find learning resources. Here are the notes I have.\n\nLocate and access resources\n\nWhen it comes to locating and accessing resources for self-directed learning, the most important things to know are:\nAdult learners often struggle with finding available resources, particularly interactive and multimedia materials. This challenge can be a significant barrier to effective self-directed learning.\nLearners should proactively identify a variety of resources beyond those provided by instructors. These can include online articles, videos, multimedia resources, books, journals, publications, blogs, and social media groups related to their learning objectives.\nTools like ChatGPT can assist in recommending relevant external resources based on personalized learning plans. However, learners should be cautious and verify the information provided by such tools.\nIt’s crucial to develop skills in searching for and accessing information, as insufficient technical skills can hinder this process. Improving these skills is an important part of self-directed learning.\n\n\nLet’s approach this systematically.\nQuestion 1:\nDo you learn better by reading, watching, or doing?\n(That’ll help decide whether to focus on docs, code examples, videos, interactive tutorials, etc.)\n\n\nI learn best by doing\n\n\nGreat—so you’ll want code-first resources, ideally with small working examples you can tinker with.\nQuestion 2:\nWhat kind of prior art do you want to learn from? For example:\n\nExisting htmlwidgets that support Shiny inputs (like DT, leaflet, plotly)?\nGeneral tutorials on writing htmlwidgets?\nTutorials or examples specifically about integrating JS events with Shiny via Shiny.setInputValue()?\nOr are you mostly looking for real widget repos to read and adapt?\n\n\n\nItems 1 and 3 on your list look good!\n\n\nGood. Then your resource categories are:\n\nReal htmlwidget packages with Shiny input support — to reverse-engineer and adapt\nTargeted examples or tutorials on using Shiny.setInputValue() inside htmlwidgets\n\nLet’s start with category 1.\nQuestion 3:\nPick one or two widgets you’ve used or are familiar with—ideally ones where clicking/selecting something in the widget updates a Shiny input. (e.g., DT::datatable, plotly::plotlyOutput). Which ones should we dissect?\n\n\nI’m mostly familar with those two you mention, more so DT then plotly tho\n\n\nPerfect. DT is a solid choice—it’s well-documented, simple enough to follow, and has clean Shiny integration.\nHere’s what I suggest for Category 1 (Prior art):\n\nPrimary resource:\n\nDT GitHub repo – especially inst/htmlwidgets/datatables.js and how it calls Shiny.setInputValue() when rows are selected.\nFocus on how selection is captured (usually via a JS event listener) and how that’s passed back to Shiny.\n\nBackup/contrast resource:\n\nplotly – check srcjs/ for how it emits click or hover events to Shiny. Slightly more complex but good for broader perspective.\n\n\nNow for Category 3 (Targeted examples of Shiny.setInputValue()):\n\n*Mini-tutorials / blogs / gists**:\n\nWinston Chang’s guide on JS &lt;-&gt; Shiny – clear and concise\nDean Attali: Custom inputs – practical advice\nRStudio’s official htmlwidgets Shiny integration doc – short, focused example\n\n\nWant me to fetch code excerpts or links for any of those right now? Or would you rather search through them yourself and come back with questions?\n\n\nThe Dean Attali post looks great and all, but the other two guides links don’t work.\n\n\nYou’re leaning into learning by doing, which means you need hands‑on code examples where you can modify and test. That’s the right approach.\nHere are solid, working resources for your two resource types:\n\n\n🧩 1. Real htmlwidget packages with Shiny input support – reverse engineering\n\nDean Attali’s “htmlwidgets tips” post explains how timevis uses JavaScript to detect item selection and sends it to Shiny:\ntimeline.on('select', properties =&gt; {\n  Shiny.onInputChange(elementId + \"_selected\", properties.items);\n});\nThis snippet, wrapped in a check for HTMLWidgets.shinyMode, ensures that Shiny receives the selected IDs via the widget’s container ID (JavaScript for R, Dean Attali).\n\n\n\n\n🎯 2. Tutorials/examples of using Shiny.setInputValue() or .onInputChange()\n\nCommunicating with Shiny via JavaScript (Posit article) covers sending values directly from JS to R using Shiny.setInputValue(id, value);. It’s the modern and preferred method (older Shiny.onInputChange() is an alias, but can still work) (Shiny).\nRyouReady blog post offers a minimal example showing an HTML div with an onclick handler that sends a random number to R via Shiny.onInputChange(\"mydata\", number) and displays it reactively server-side (“R” you ready?).\n\n\n\n✅ Quick Comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResource\n\nWhy it helps\n\nFocus on\n\n\n\n\n\n\n\n\n\n\n\n\n\nDean Attali (“htmlwidgets tips”)\n\nReal widget code invoking JS event + input change\n\ntimeline.on('select', ...) and chaining to Shiny\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosit “Communicating with JS”\n\nModern API and rationale\n\nShiny.setInputValue(...) inside a listener\n\n\n\n\n\n\n\n\n\n\n\n\n\nRyouReady blog\n\nMinimal standalone JS ↔︎ R demo\n\nUsing Shiny.onInputChange in UI and reading input$mydata in server\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n📌 Suggested next step\nPick one real widget example (like timevis or similar) and one minimal demo. Then:\n\nReview the JS code where selection events are handled and Shiny.setInputValue() (or .onInputChange()) is called.\nModify your widget JS similarly—hook into user’s event selection and send the event ID (or index) via Shiny.setInputValue().\nAdd reactive code in your server to observe input$&lt;widgetId&gt;_selected and log or display it.\nBuild a minimal working Shiny app with your widget and observe whether it captures user clicks.\nWant me to pull that specific “page code” from the timevis repo or the Attali post so you can step through it?\n\n\n\n\n\nWait, can you find me more resources? I don’t want to learn from your summaries\n\n\nHere’s a curated list of solid, hands‑on resources to go beyond summaries and dive into real working code you can adapt:\n\n\n🔧 Real htmlwidget packages with Shiny input support\n\nDean Attali — “How to write a useful htmlwidgets in R: tips and walk‑through a real example”\n\nDeals directly with timevis and how it handles events: it includes a live example of passing selections back to Shiny via JavaScript callbacks CRAN+8Dean Attali+8Stack Overflow+8Shiny+2r4ds.github.io+2engineering-shiny.org+2.\n“Widgets with Shiny” ‑ JavaScript for R book (Chapter 17)\n\nCovers patterns for embedding event handlers in widget JS and using Shiny.setInputValue() in the context of htmlwidgets JavaScript for Rdatanovia+3engineering-shiny.org+3Stack Overflow+3.\n\n\n\n\n🧠 Tutorials and minimal examples on Shiny.setInputValue()\n\nPosit article — “Communicating with Shiny via JavaScript”\n\nConcise and modern: shows core usage of Shiny.setInputValue(id, value) and the optional {priority: \"event\"} flag to treat values as events rstudio.github.io+7Shiny+7r4ds.github.io+7.\n“How to build a JavaScript‑based widget” by Posit\n\nBuilds an example widget using D3/C3 and includes code on client‑server communication with Shiny (including setInputValue) Shiny+1JavaScript for R+1.\nR for Data Science Bookclub: “JavaScript ↔︎ Shiny Communication”\n\nOffers compact code snippets showing how to send data back using Shiny.setInputValue and receive it in R with reactive observers htmlwidgets.org+15r4ds.github.io+15datanovia+15.\n\n\n\n\n📚 JavaScript integration & custom input patterns\n\nDatanovia article — “JavaScript Integration and Custom Functionality: Extend Shiny Beyond R” (May 2025)\n\nA recent and comprehensive guide to advanced interaction patterns, custom bindings, and message passing between JS and Shiny JavaScript for R+2datanovia+2CRAN+2.\n\n\n\n\n🧪 StackOverflow & minimal snippets\n\nSO Example — Reactable row click setting input value in Shiny modules\n\nShows how onClick handlers call Shiny.setInputValue() to pass selected row data into R, along with observeEvent responses Stack Overflow+1engineering-shiny.org+1.\nSO thread — Reading selection from radialNetworkR htmlwidget in Shiny\n\nIllustrates a real-world case where someone needed to capture user selection in a custom widget, and references using Tip 7a from Dean’s blog for guidance search.r-project.org+10Stack Overflow+10nielsenmark.us+10.\n\n\n\n\n📋 Summary Table\n\n\n\n\n\n\n\n\nResource\nUse Case\nWhat you’ll get\n\n\n\n\nDean Attali (timevis code)\nReal-world widget code\nUnderstand how JS event to Shiny input is implemented\n\n\nPosit JS‑Shiny tutorial\nCore API\nClean examples of Shiny.setInputValue() usage\n\n\nJS for R book (Chapter 17)\nIn‑widget integration\nFull example of wiring JS and htmlwidgets with Shiny\n\n\nDatanovia (May 2025)\nAdvanced patterns\nModern perspectives on custom input and messaging\n\n\nSO posts (Reactable, radialNetworkR)\nMinimal demos\nConcrete handlers showing event → R logic"
  },
  {
    "objectID": "posts/llms_for_learning/index.html#real-htmlwidget-packages-with-shiny-input-support-reverse-engineering",
    "href": "posts/llms_for_learning/index.html#real-htmlwidget-packages-with-shiny-input-support-reverse-engineering",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "🧩 1. Real htmlwidget packages with Shiny input support – reverse engineering",
    "text": "🧩 1. Real htmlwidget packages with Shiny input support – reverse engineering\n\nDean Attali’s “htmlwidgets tips” post explains how timevis uses JavaScript to detect item selection and sends it to Shiny:\ntimeline.on('select', properties =&gt; {\n  Shiny.onInputChange(elementId + \"_selected\", properties.items);\n});\nThis snippet, wrapped in a check for HTMLWidgets.shinyMode, ensures that Shiny receives the selected IDs via the widget’s container ID (JavaScript for R, Dean Attali)."
  },
  {
    "objectID": "posts/llms_for_learning/index.html#tutorialsexamples-of-using-shiny.setinputvalue-or-.oninputchange",
    "href": "posts/llms_for_learning/index.html#tutorialsexamples-of-using-shiny.setinputvalue-or-.oninputchange",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "🎯 2. Tutorials/examples of using Shiny.setInputValue() or .onInputChange()",
    "text": "🎯 2. Tutorials/examples of using Shiny.setInputValue() or .onInputChange()\n\nCommunicating with Shiny via JavaScript (Posit article) covers sending values directly from JS to R using Shiny.setInputValue(id, value);. It’s the modern and preferred method (older Shiny.onInputChange() is an alias, but can still work) (Shiny).\nRyouReady blog post offers a minimal example showing an HTML div with an onclick handler that sends a random number to R via Shiny.onInputChange(\"mydata\", number) and displays it reactively server-side (“R” you ready?).\n\n\n\n✅ Quick Comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResource\n\nWhy it helps\n\nFocus on\n\n\n\n\n\n\n\n\n\n\n\n\n\nDean Attali (“htmlwidgets tips”)\n\nReal widget code invoking JS event + input change\n\ntimeline.on('select', ...) and chaining to Shiny\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosit “Communicating with JS”\n\nModern API and rationale\n\nShiny.setInputValue(...) inside a listener\n\n\n\n\n\n\n\n\n\n\n\n\n\nRyouReady blog\n\nMinimal standalone JS ↔︎ R demo\n\nUsing Shiny.onInputChange in UI and reading input$mydata in server\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n📌 Suggested next step\nPick one real widget example (like timevis or similar) and one minimal demo. Then:\n\nReview the JS code where selection events are handled and Shiny.setInputValue() (or .onInputChange()) is called.\nModify your widget JS similarly—hook into user’s event selection and send the event ID (or index) via Shiny.setInputValue().\nAdd reactive code in your server to observe input$&lt;widgetId&gt;_selected and log or display it.\nBuild a minimal working Shiny app with your widget and observe whether it captures user clicks.\nWant me to pull that specific “page code” from the timevis repo or the Attali post so you can step through it?"
  },
  {
    "objectID": "posts/llms_for_learning/index.html#step-3---adopt-and-execute-learning-activties",
    "href": "posts/llms_for_learning/index.html#step-3---adopt-and-execute-learning-activties",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "Step 3 - Adopt and Execute Learning Activties",
    "text": "Step 3 - Adopt and Execute Learning Activties\nDuration: 36 minutes\nThe third and final step was the most useful by far!\nOnce again, I pasted in the guide to this step, and ChatGPT created a plan for me containing four items:\n\nReverse-engineer one working widget\nBuild minimal standalone Shiny demo\nAdd minimal event tracking to your widget\nWire the widget into a basic Shiny app\n\nThis was actually pretty impressive; each step contained a goal, the steps required to achieve it, suggestions for how an LLM could help, and a timebox of how long to spend on each activity.\nHere’s the first activity suggested:\n\n🔍 1. Reverse-engineer one working widget\nGoal: Understand how an existing widget (e.g. DT) captures selection and sends it to Shiny.\nActivity:\n\nOpen the DT GitHub repo.\nLocate where Shiny.setInputValue() is used in the JS files (inst/htmlwidgets/datatables.js).\nMake brief notes:\n\nWhat JS event triggers the update?\nHow is the input ID constructed?\nWhat data is passed to Shiny?\n\n\nLLM Role:\n\nAsk ChatGPT to walk you through unfamiliar lines or patterns (e.g. “What’s this event handler doing?” or “What does this argument to setInputValue mean?”).\n\nTimebox: 20–30 minutes.\n\nI walked through each activity, setting a timer on my phone. I found that I completed each in less than the allotted time. I skipped the last activtity, as I only required 1-3 to complete the task.\n\n\n\n\n\n\nExpand to view learning plan\n\n\n\n\n\n\nOK, my next step is below\n\nAdopt and Execute Learning Activties\n\nAdopting and executing learning activities is a crucial task in self-directed learning. This step involves developing a specific plan of action that aligns with established goals and available resources.\nLearners should create tailored plans that consider their preferred learning styles and available time for learning. This personalization helps ensure the learning activities are effective and manageable.\nTime-management techniques, such as spaced repetition and active recall, are important to incorporate into the learning plan. These strategies can help learners stay on track and optimize their learning process.\nLearning activities should be diverse and match the learner’s preferred style. This might include visual aids, podcasts, reading materials, or hands-on activities, depending on whether the learner is visual, auditory, reading/writing, or kinesthetic.\nSupplementing core learning activities with additional resources, such as online workshops, can enhance the learning experience and provide different perspectives on the subject matter.\n\n\n🛠️ Execution Plan: LLM-Assisted Learning Without Code Outsourcing\n\n⏱️ Estimated Total Time: ~2–3 hours\n\n\n\n🔍 1. Reverse-engineer one working widget\nGoal: Understand how an existing widget (e.g. DT) captures selection and sends it to Shiny.\nActivity:\n\nOpen the DT GitHub repo.\nLocate where Shiny.setInputValue() is used in the JS files (inst/htmlwidgets/datatables.js).\nMake brief notes:\n\nWhat JS event triggers the update?\nHow is the input ID constructed?\nWhat data is passed to Shiny?\n\n\nLLM Role:\n\nAsk ChatGPT to walk you through unfamiliar lines or patterns (e.g. “What’s this event handler doing?” or “What does this argument to setInputValue mean?”).\n\nTimebox: 20–30 minutes.\n\n\n\n🧪 2. Build minimal standalone Shiny demo\nGoal: Create a toy Shiny app where JS sends a value to R.\nActivity:\n\nUse this Posit guide or RyouReady’s example to build a plain HTML div or button that triggers Shiny.setInputValue() in a browser console or inline JS.\n\nLLM Role:\n\nAsk it to review the minimal app you’ve built and explain/debug if input isn’t showing up server-side.\n\nTimebox: 20 minutes.\n\n\n\n🧱 3. Add minimal event tracking to your widget\nGoal: Modify your widget to track one user interaction and send something to Shiny.\nActivity:\n\nIn your widget’s JS binding, add an event listener (e.g. click/select).\nSend a dummy value to Shiny using Shiny.setInputValue().\nObserve input in input$yourwidget_selected or similar.\n\nLLM Role:\n\nAsk for feedback on the specific event binding you’re trying (“Why isn’t this firing?” or “What selector do I use to bind the click?”).\n\nTimebox: 45–60 minutes.\n\n\n\n🧪 4. Wire the widget into a basic Shiny app\nGoal: End-to-end test: selection in your timeline → reactive output in Shiny.\nActivity:\n\nWrite a basic Shiny app using your widget.\nUse reactivePrint(), observeEvent(), or renderText() to display the selected item.\n\nLLM Role:\n\nAsk it to sanity check your Shiny app logic or spot input ID mismatches.\n\nTimebox: 30 minutes.\n\n\n\nOptional: 🔁 Space repetition (1–2 days later)\nCome back and:\n\nRebuild the Shiny example from scratch.\nAdd a new input (e.g. multiple selection).\nExplain the flow (JS → R) out loud or in a notebook.\n\n\n\n\n✅ How I can help\nYou run the show. Use me like a senior dev standing over your shoulder:\n\n“Explain this line of JS.”\n“This event handler isn’t firing—what’s wrong?”\n“What’s the right selector for this DOM node?”\n“Can you sanity-check this widget binding?”\n“What’s the minimal Shiny app I can use to test this?”\n\n\nWant a markdown checklist version of this plan to copy into your notes?\n\n\n\n\n\nThere was a lot of interaction between me and ChatGPT here, and I’m not going to paste it all, but essentially, during the time I used it to:\n\nexplain some JavaScript code I didn’t understand by walking me through it line-by-line\nget clarity on how to implement some of its suggestions by asking exactly what it meant\nmultiple rounds of debugging code I had wrote which didn’t work\nhelping me work out exactly where the change was needed in my own code\n\nIn the last example, ChatGPT didn’t just tell me where to put the code, but walked through the important concepts to reason through the answer. It then asked me questions so that I could work out where in the code the change needed to go. Here’s a snippet from that interaction.\n\n🤔 So… where do you want interactivity?\nLet me ask you this:\n\nOut of everything that’s being created here, what part of the DOM would the user actually click on if they were selecting a timeline event?\n\nOnce we know that, we can talk about how and where to attach the event handler.\n\n\n\nI think they’d click on the timeline-box element\n\n\n\nExactly—that’s the actionable node.\nThat means you’ll want to attach a JS event handler (e.g. .onclick or .addEventListener('click', ...)) to each .timeline-box as it’s created.\nNow a follow-up:\n\nWhen you’re looping over x.events, what info do you need to send back to Shiny when a .timeline-box is clicked? (Think: what identifier, value, or payload do you want to capture?)\n\n\nWe carried on the back and forth like this for a while, with ChatGPT asking me questions to guide me towards the solution. If I got an answer wrong, it replied with an encouraging tone and explained why I was incorrect, and the specific piece of knowledge I was missing.\nEventually, we go to the end of our interaction.\n\nIt’s working!!\n\n\n\nExcellent. That means your widget is now:\n\nRendering cleanly ✅\nSending input to Shiny ✅\nUpdating on click ✅\n\nYou’ve now got the full JS → R feedback loop working in your custom htmlwidget.\n\nIf you want to improve it later, next steps could include:\n\nMaking the selected element visually highlighted (add/remove a CSS class)\nSending richer data to Shiny (e.g. event ID, label, timestamp)\nSupporting multiple selection or deselection\nWriting a unit test or snapshot test for the widget rendering\n\n\n\nBut honestly—you’ve just crossed the hardest barrier. Nice work.\n\n\nAnything else you want to do with it right now?\n\n\nIt sounds like a lot, but this whole experience took around 1 hour from end to end which I found pretty impressive."
  },
  {
    "objectID": "posts/llms_for_learning/index.html#execution-plan-llm-assisted-learning-without-code-outsourcing",
    "href": "posts/llms_for_learning/index.html#execution-plan-llm-assisted-learning-without-code-outsourcing",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "🛠️ Execution Plan: LLM-Assisted Learning Without Code Outsourcing",
    "text": "🛠️ Execution Plan: LLM-Assisted Learning Without Code Outsourcing\n\n⏱️ Estimated Total Time: ~2–3 hours\n\n\n\n🔍 1. Reverse-engineer one working widget\nGoal: Understand how an existing widget (e.g. DT) captures selection and sends it to Shiny.\nActivity:\n\nOpen the DT GitHub repo.\nLocate where Shiny.setInputValue() is used in the JS files (inst/htmlwidgets/datatables.js).\nMake brief notes:\n\nWhat JS event triggers the update?\nHow is the input ID constructed?\nWhat data is passed to Shiny?\n\n\nLLM Role:\n\nAsk ChatGPT to walk you through unfamiliar lines or patterns (e.g. “What’s this event handler doing?” or “What does this argument to setInputValue mean?”).\n\nTimebox: 20–30 minutes.\n\n\n\n🧪 2. Build minimal standalone Shiny demo\nGoal: Create a toy Shiny app where JS sends a value to R.\nActivity:\n\nUse this Posit guide or RyouReady’s example to build a plain HTML div or button that triggers Shiny.setInputValue() in a browser console or inline JS.\n\nLLM Role:\n\nAsk it to review the minimal app you’ve built and explain/debug if input isn’t showing up server-side.\n\nTimebox: 20 minutes.\n\n\n\n🧱 3. Add minimal event tracking to your widget\nGoal: Modify your widget to track one user interaction and send something to Shiny.\nActivity:\n\nIn your widget’s JS binding, add an event listener (e.g. click/select).\nSend a dummy value to Shiny using Shiny.setInputValue().\nObserve input in input$yourwidget_selected or similar.\n\nLLM Role:\n\nAsk for feedback on the specific event binding you’re trying (“Why isn’t this firing?” or “What selector do I use to bind the click?”).\n\nTimebox: 45–60 minutes.\n\n\n\n🧪 4. Wire the widget into a basic Shiny app\nGoal: End-to-end test: selection in your timeline → reactive output in Shiny.\nActivity:\n\nWrite a basic Shiny app using your widget.\nUse reactivePrint(), observeEvent(), or renderText() to display the selected item.\n\nLLM Role:\n\nAsk it to sanity check your Shiny app logic or spot input ID mismatches.\n\nTimebox: 30 minutes.\n\n\n\nOptional: 🔁 Space repetition (1–2 days later)\nCome back and:\n\nRebuild the Shiny example from scratch.\nAdd a new input (e.g. multiple selection).\nExplain the flow (JS → R) out loud or in a notebook.\n\n\n\n\n✅ How I can help\nYou run the show. Use me like a senior dev standing over your shoulder:\n\n“Explain this line of JS.”\n“This event handler isn’t firing—what’s wrong?”\n“What’s the right selector for this DOM node?”\n“Can you sanity-check this widget binding?”\n“What’s the minimal Shiny app I can use to test this?”\n\n\nWant a markdown checklist version of this plan to copy into your notes?"
  },
  {
    "objectID": "posts/llms_for_learning/index.html#the-final-output",
    "href": "posts/llms_for_learning/index.html#the-final-output",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "The final output",
    "text": "The final output\nHere is the final PR: https://github.com/thisisnic/daisyuiwidget/pull/11. It’s not particularly complicated, but in the hour it took to write, I learned about some of the internals of the DT package, created a standalone example of sending information between JavaScript and R, and then implemented this in the package."
  },
  {
    "objectID": "posts/llms_for_learning/index.html#takeaways-from-a-structured-llm-learning-session",
    "href": "posts/llms_for_learning/index.html#takeaways-from-a-structured-llm-learning-session",
    "title": "Using ChatGPT as a Code Tutor: A One-Hour Learning Experiment",
    "section": "Takeaways from a structured LLM Learning session",
    "text": "Takeaways from a structured LLM Learning session\nWhat made this work wasn’t that ChatGPT giving me the right code but that it helped me ask the right questions. It acted like a more senior engineer, talking me through unfamiliar concepts, helping me debug my code, and nudging me towards the right mental model.\n\nLess overhead, faster feedback\nIt helped reduce context-switching and help me stay in flow. I didn’t need to spend time refining my overall goal, deciding what steps to take, and skim through partially relevant resources. By instead being able to focusing solely on writing the code, it prevented the cognitive fatigue of having to switch between “coding” and “planning” mindsets.\n\n\nStill my own work\nCould I have done it without the LLM? Yes, but it would have taken longer, and I would have learned less.\nAlthough I was using an LLM, I was an active participant in my own learning and so felt empowered as a learner. ChatGPT provided scaffolding and support but not all of the answers.\n\n\nWhat I’d change next time\nA reasonable next step to develop this idea further would be to refine the prompts for each stage - the prompts I included were just summaries of the snippets of the article, rather than specific instructions for ChatGPT. In small tasks like this, I’d treat information gathering as part of the task, and collapse steps 2 and 3.\nI found this process really rewarding to try out, and I’d encourage others to give it a go. Let me know how you get on if you do!"
  },
  {
    "objectID": "projects/phd/index.html",
    "href": "projects/phd/index.html",
    "title": "PhD Thesis - Debiasing Reasoning: A Signal Detection Analysis",
    "section": "",
    "text": "Download here: PDF, 2.1MB\nThis thesis focuses on deductive reasoning and how the belief bias effect can be reduced or ameliorated.\nBelief bias is a phenomenon whereby the evaluation of the logical validity of an argument is skewed by the degree to which the reasoner believes the conclusion. There has been little research examining ways of reducing such bias and whether there is some sort of effective intervention which makes people reason more on the basis of logic. Traditional analyses of this data has focussed on simple measures of accuracy, typically deducting the number of incorrect answers from the number of correct answers to give an accuracy score. However, recent theoretical developments have shown that this approach fails to separate reasoning biases and response biases. A reasoning bias, is one which affects individuals’ ability to discriminate between valid and invalid arguments, whereas a response bias is simply the individual’s tendency to give a particular answer, independent of reasoning. A Signal Detection Theory (SDT) approach is used to calculate measures of reasoning accuracy and response bias. These measures are then analysed using mixed effects models.\nChapter 1 gives a general introduction to the topic, and outlines the content of subsequent chapters. In Chapter 2, I review the psychological literature around belief bias, the growth of the use of SDT models, and approaches to reducing bias. Chapter 3 covers the methodology, and includes a a thorough description of the calculation of the SDT measures, and an explanation of the mixed effects models I used to analyse these. Chapter 4 presents an experiment in which the effects of feedback on reducing belief bias is examined. In Chapter 5, the focus shifts in the direction of individual differences, and looks at the effect of different instructions given to participants, and Chapter 6 examines the effects of both feedback and specific training. Chapter 7 provides a general discussion of the implications of the previous three chapters."
  },
  {
    "objectID": "projects/firstcontributions/index.html",
    "href": "projects/firstcontributions/index.html",
    "title": "First Contributions (in R) Repo",
    "section": "",
    "text": "A GitHub repository helping people make their first open source PR. The repo is a chopped-up, trimmed-down, and customised-for-RStudio version of the amazing first contributions repo designed to act as a live tutorial for people making their first open source pull request. Kindly taken over by Forwards who now manage it."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Me",
    "section": "",
    "text": "Loading…"
  },
  {
    "objectID": "talks/londonr/index.html",
    "href": "talks/londonr/index.html",
    "title": "Ten Steps To Becoming A Tidyverse Contributor",
    "section": "",
    "text": "A talk about getting involved in open source!\nSlides here"
  },
  {
    "objectID": "talks/positconf2024_2/index.html",
    "href": "talks/positconf2024_2/index.html",
    "title": "Mixing R, Python, and Quarto: Crafting the Perfect Open Source Cocktail",
    "section": "",
    "text": "A talk on Arrow that Alenka Frim and I wrote and presented at posit::conf 2024.\nhttps://docs.google.com/presentation/d/1ViXduR7CNrz_9QFDk5snAlD3tFJpJs156-UEBxCHiks/edit?usp=sharing"
  },
  {
    "objectID": "talks/rstudioconf2022/index.html",
    "href": "talks/rstudioconf2022/index.html",
    "title": "What they forgot to teach you about becoming an open source contributor",
    "section": "",
    "text": "Getting involved in open source is an amazing learning experience and helps you grow your skills as a developer, but to a new contributor there are so many unknown factors about open source projects. In this talk, I’m going to discuss my journey from occasional open source contributor to full time project maintainer, and answer questions such as: what does it look like from the inside of an open-source project? What’s a good way to get involved, and really learn the internals of an R package? How can I navigate the social dynamics of an open source project? How do contributions look entirely different from the point of view of a contributor versus a maintainer?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nic Crane, PhD",
    "section": "",
    "text": "Hi, I’m Nic! I’m a data scientist, software engineer, and R enthusiast. I am part of the team who maintain the arrow R package and co-author of Scaling Up with R and Arrow.\nI also provide professional, tailored consulting and training services to help organisations unlock the full potential of R and data analysis. With extensive experience in developing Shiny apps and dashboard, modernising legacy code, building R packages, and designing data visualization and automated reporting tools, I focus on delivering effective solutions that meet specific client needs and help you get more from your data.\n\nConsulting Expertise\n\nShiny app development: End-to-end creation of interactive dashboards, including:\n\nA Shiny portal designed to monitor the status of genomic analysis pipelines for a large-scale healthcare organization.\nAn app built to automate data cleaning and visualization for a major pharmaceutical company.\nOptimization and redesign of an existing Shiny app for a semiconductor manufacturer, applying best software engineering practices.\n\nLegacy code modernization: Transitioning from SAS or Excel to R for streamlined analysis.\nDiverse technical solutions: A complete Python-based NLP solution, including a backend and dashboard, to analyze online reviews and extract themes and aggregated sentiments for a university project.\n\nOpen to both short-term problem-solving projects and longer-term collaborations.\n\n\nTraining Services\n\nBeginner to advanced topics, including R fundamentals, Apache Arrow for big data, and AI-powered workflows.\nCustomised courses tailored to your needs, ensuring relevance and hands-on learning.\nProven track record, with workshops taught at EARL, posit::conf and online courses developed for major platforms.\n\n\n\nWhy Work with Me?\n\nTrusted reputation in the R community, with open-source contributions and public speaking engagements at industry-leading events.\nFlexible, remote-friendly services, ensuring cost-effective, high-quality results.\nTransparent communication, with clear deliverables, timelines, and scope management.\n\nI’m currently accepting new clients and open to partnerships for larger projects. Whether you’re looking to upskill your team, modernise your workflows, or tackle a specific data challenge, I’d love to discuss how I can help.\nContact me"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Scaling Up With R and Arrow\n\n\n\n\n\n\nNic Crane\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Contributions (in R) Repo\n\n\n\n\n\n\nNic Crane\n\n\nNov 28, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhD Thesis - Debiasing Reasoning: A Signal Detection Analysis\n\n\n\n\n\n\nNic Crane\n\n\nJul 22, 2016\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/nyhackr/index.html",
    "href": "talks/nyhackr/index.html",
    "title": "Efficiently Engineering Bigger Data with Arrow",
    "section": "",
    "text": "Data analysis pipelines with larger-than-memory data are becoming more and more commonplace. There are often blurred lines between data science and data engineering, and knowing a bit of both is a sure-fire way to make your life easier when working with big datasets. In this talk, I will give an overview of the arrow R package and best practices for getting the most out of your data when working with bigger datasets. I’ll demo the dplyr interface to arrow, and give you some tips and tricks for getting the most out of arrow’s functionality, as well as applying data engineering principles to speed things up even more."
  },
  {
    "objectID": "talks/positconf2024/index.html",
    "href": "talks/positconf2024/index.html",
    "title": "Big Data in R with Arrow",
    "section": "",
    "text": "A workshop on Arrow that Stephanie Hazlitt and I wrote and presented at posit::conf 2023 and 2024.\nCourse homepage"
  },
  {
    "objectID": "talks/positconf2024/index.html#overview",
    "href": "talks/positconf2024/index.html#overview",
    "title": "Big Data in R with Arrow",
    "section": "Overview",
    "text": "Overview\nData analysis pipelines with larger-than-memory data are becoming more and more commonplace. In this workshop you will learn how to use Apache Arrow, a multi-language toolbox for working with larger-than-memory tabular data, to create seamless “big” data analysis pipelines with R.\nThe workshop will focus on using the the arrow R package—a mature R interface to Apache Arrow—to process larger-than-memory files and multi-file datasets with arrow using familiar dplyr syntax. You’ll learn to create and use interoperable data file formats like Parquet for efficient data storage and access, with data stored both on disk and in the cloud, and also how to exercise fine control over data types to avoid common large data pipeline problems. This workshop will provide a foundation for using Arrow, giving you access to a powerful suite of tools for performant analysis of larger-than-memory data in R.\nThis course is for you if you:\n\nwant to learn how to work with tabular data that is too large to fit in memory using existing R and tidyverse syntax implemented in Arrow\nwant to learn about Parquet and other file formats that are powerful alternatives to CSV files\nwant to learn how to engineer your tabular data storage for more performant access and analysis with Apache Arrow"
  },
  {
    "objectID": "talks/rstudioconf2019/index.html",
    "href": "talks/rstudioconf2019/index.html",
    "title": "The future’s Shiny: Pioneering genomic medicine in R",
    "section": "",
    "text": "Shiny's expanding capabilities are rapidly transforming how it is used in an enterprise. This talk details the creation of a large-scale application, supporting hundreds of concurrent users, making use of the future and promises packages. The 100,000 genomes project is an ambitious exercise that follows on from the Human Genome Project - aiming to put the UK at the forefront of genomic medicine, with the NHS as the first health service in the world to offer precision medicine to patients with rare diseases and cancer. Data is at the heart of this project; not only the outputs of the genomic sequencing, but vast amounts of metadata used to track progress against the 100,000 genome target and the status and path of each case through the sample tracking pipeline. In order to make this data readily available to stakeholders, Shiny was used to create an application containing multiple interactive dashboards. A scaled-up version of the app is being rolled out in early 2019 to a much larger audience to support the National Genomics Informatics Service, with the challenge of creating a complex app capable of supporting so many users without grinding to a halt. In this talk, I will explain why Shiny was the obvious technology choice for this task, and discuss the design decisions which enabled this project’s success."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks and Workshops",
    "section": "",
    "text": "Mixing R, Python, and Quarto: Crafting the Perfect Open Source Cocktail\n\n\n\n\n\n\nNic Crane\n\n\nAug 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nBig Data in R with Arrow\n\n\n\n\n\n\nNic Crane\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficiently Engineering Bigger Data with Arrow\n\n\n\n\n\n\nNic Crane\n\n\nAug 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat they forgot to teach you about becoming an open source contributor\n\n\n\n\n\n\nNic Crane\n\n\nJul 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe future’s Shiny: Pioneering genomic medicine in R\n\n\n\n\n\n\nNic Crane\n\n\nJan 17, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\nTen Steps To Becoming A Tidyverse Contributor\n\n\n\n\n\n\nNic Crane\n\n\nNov 27, 2018\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/book/index.html",
    "href": "projects/book/index.html",
    "title": "Scaling Up With R and Arrow",
    "section": "",
    "text": "Published online for free at arrowrbook.com\nA book I co-authored with Jonathan Keane and Neal Richardson about working with larger-than-memory datasets in R with Arrow. The paper version will be published later this year."
  },
  {
    "objectID": "posts/rwatcher/index.html",
    "href": "posts/rwatcher/index.html",
    "title": "Monitoring R Package Updates with Github Actions",
    "section": "",
    "text": "As maintainer of the Arrow R package, there are a few packages I want to keep up to date with, so I can make sure that our bindings continue to be compatible with the latest versions of these packages. The packages I’m most interested in here are:\nI’m also interested in knowing when packages that folks use for vaguely similar purposes have been updated; I like to be up-to-date on this as sometimes people ask me about how things compare.\nPreviously, I’d occasionally caught glimpses of things via social media, but I wanted a more methodical approach, and so decided to write a GitHub Actions CRON job that does this. Now, when any of the packages on my list is updated, I receive an email that looks a little like this:\nIn this blog post, I’m going to walk through how I created this repository, and how you can do the same for your own packages."
  },
  {
    "objectID": "posts/rwatcher/index.html#how-it-all-works",
    "href": "posts/rwatcher/index.html#how-it-all-works",
    "title": "Monitoring R Package Updates with Github Actions",
    "section": "How it all works",
    "text": "How it all works\nThe repo itself it pretty simple in structure - it contains the GitHub Actions workflow, and a folder containing the changelogs for the packages I’m interested in.\n# tree\n.github\n└── workflows\n    └── compare_hashes.yml\nchangelogs\n├── data.table-NEWS.md\n├── dbplyr-NEWS.md\n├── dplyr-NEWS.md\n├── dtplyr-NEWS.md\n├── duckdb-NEWS.md\n├── duckplyr-NEWS.md\n├── lubridate-NEWS.md\n├── r-polars-NEWS.md\n├── stringr-NEWS.md\n└── tidypolars-NEWS.md\nThe workflow is triggered every day at 1am UTC, and runs a script that compares the hashes of the changelogs in my repo with the hashes of the changelogs in the package repos. If there’s a difference, the new changelog is saved to my repo and it sends me an email."
  },
  {
    "objectID": "posts/rwatcher/index.html#the-github-actions-workflow",
    "href": "posts/rwatcher/index.html#the-github-actions-workflow",
    "title": "Monitoring R Package Updates with Github Actions",
    "section": "The GitHub Actions Workflow",
    "text": "The GitHub Actions Workflow\nIn the next sections, I’ll walk through the GitHub Actions workflow, step by step, explaining what each bit does.\n\nScheduling\nThe start of the workflow looks like this:\nname: Check for package updates\n\non:\n  schedule:\n    # * is a special character in YAML so you have to quote this string\n    - cron:  '00 1 * * *'\nIt has a name, and the schedule is set to run every day at 1am UTC. The cron syntax is a bit weird, but there’s a handy crontab guru that can help you figure out what you need to put in here.\n\n\nJobs\nNext, we set up the different jobs we want to run. I want 1 job to run for each package.\nI used GitHub Copilot to help me with some of the syntax here; it was fantastic when I just added a comment describing what I’d like to be added, and then it filled it in. This wasn’t a perfect process as you have to know what to ask, and setting up the list of packages to work with was tricky, as I didn’t quite have the understanding of how matrices (which can run code in parallel) interacted with arrays (for specifying multiple inputs for each parallel job) as I hadn’t used this before. A bit of googling and a skim of StackOverflow and I got there pretty quickly though.\njobs:\n  compare-hashes:\n    name: ${{matrix.package.name}} updates\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    strategy:\n        matrix:\n          package: \n            [\n                { name: dbplyr, file: dbplyr-NEWS.md, url: 'https://raw.githubusercontent.com/tidyverse/dbplyr/main/NEWS.md' }, \n                { name: lubridate, file: lubridate-NEWS.md, url: 'https://raw.githubusercontent.com/tidyverse/lubridate/main/NEWS.md' },\n                { name: dplyr, file: dplyr-NEWS.md, url: 'https://raw.githubusercontent.com/tidyverse/dplyr/main/NEWS.md'}, \n                { name: data.table, file: data.table-NEWS.md, url: 'https://raw.githubusercontent.com/Rdatatable/data.table/master/NEWS.md'},\n                { name: dtplyr, file: dtplyr-NEWS.md, url: 'https://raw.githubusercontent.com/tidyverse/dtplyr/main/NEWS.md'},\n                { name: duckdb-r, file: duckdb-r-NEWS.md, url: 'https://raw.githubusercontent.com/duckdb/duckdb-r/main/NEWS.md'},\n                { name: r-polars, file: r-polars-NEWS.md, url: 'https://raw.githubusercontent.com/pola-rs/r-polars/main/NEWS.md'},\n                { name: stringr, file: stringr-NEWS.md, url: 'https://raw.githubusercontent.com/tidyverse/stringr/main/NEWS.md'},\n                { name: duckplyr, file: duckplyr-NEWS.md, url: 'https://raw.githubusercontent.com/duckdblabs/duckplyr/main/NEWS.md'},\n                { name: tidypolars, file: tidypolars-NEWS.md, url: 'https://raw.githubusercontent.com/etiennebacher/tidypolars/main/NEWS.md'},\n            ]\nThe runs-on specifies the operating system to run the job on, and the permissions section allows the job to write to the repo. The strategy section is where we set up the matrix of packages to work with. Each package has a name, a file name, and a URL to the changelog. The name of the job is set to the name of the package.\n\n\nSteps\nNext, we set up the steps that we want to run. The first step is to check out the repo we are working in, and get the hash of the relevant changelog file I have stored in my repo. This is saved to the GITHUB_OUTPUT environment variable, which is a file that is shared between all the steps in the job.\n    steps:\n        - name: Checkout code\n          uses: actions/checkout@v2\n        - name: Get local file hash\n          id: local-hash\n          run: echo \"local_hash=$(md5sum changelogs/${{ matrix.package.file }} | cut -d ' ' -f 1)\" &gt;&gt; $GITHUB_OUTPUT\nNext, I want to get the hash of the latest version of the package’s changelog file. I do this by downloading the file, and then getting the hash of the downloaded file. This is also saved to the GITHUB_OUTPUT environment variable.\n        - name: Get remote file\n          id: remote-file\n          run: |\n                  mkdir tmp\n                  curl -s ${{ matrix.package.url }} &gt; tmp/${{ matrix.package.file }}#\n        - name: Get remote file hash\n          id: remote-hash\n          run: echo \"remote_hash=$(md5sum tmp/${{ matrix.package.file }} | cut -d ' ' -f 1)\" &gt;&gt; $GITHUB_OUTPUT\nFinally, I want to compare the hashes of the two files. If they’re different, I want to update the changelog in my repo. I do this by setting up a conditional step that only runs if the hashes are different. In this case, I’m setting the git config, copying the new changelog to my repo, and then committing and pushing the changes.\n        - name: Update changed files\n          if: ${{ steps.local-hash.outputs.local_hash != steps.remote-hash.outputs.remote_hash }}\n          run: |\n            echo \"Hashes do not match!\"   \n            git config --global user.email \"github-actions[bot]@users.noreply.github.com\"\n            git config --global user.name \"GHA Bot\"\n            cp tmp/${{ matrix.package.file }} changelogs/${{ matrix.package.file }}\n            git add changelogs/${{ matrix.package.file }}\n            git pull --ff-only\n            git commit -m \"Update ${{matrix.package.name}} changelog\"\n            git push\nFinally, I want to send an email notification if the changelog has been updated. I do this by setting up a conditional step that only runs if the hashes are different. I use the dawidd6/action-send-mail action to send the email. I set up a few secrets in my repo to store the email address and password, and then use those in the action. I also set up the subject and body of the email using the package name and URL.\nThe username and password are not my actual email address and password; instead, you can set up an app password for your email account, and use that instead, which is more secure.\n        - name: Send email notification\n          if: ${{ steps.local-hash.outputs.local_hash != steps.remote-hash.outputs.remote_hash }}\n          uses: dawidd6/action-send-mail@v3\n          with:\n            server_address: smtp.gmail.com\n            server_port: 465\n            username: ${{ secrets.MAIL_USERNAME }}\n            password: ${{ secrets.MAIL_PASSWORD }}\n            subject: \"${{matrix.package.name}} update\"\n            body: \"${{matrix.package.name}} has been updated! Please check the changelog at ${{matrix.package.url}}.\"\n            to: ${{ secrets.MAIL_RECIPIENT }}\n            from: ${{ secrets.MAIL_USERNAME}}\nAnd that’s it! The full repository can be found here."
  },
  {
    "objectID": "posts/rwatcher/index.html#conclusion",
    "href": "posts/rwatcher/index.html#conclusion",
    "title": "Monitoring R Package Updates with Github Actions",
    "section": "Conclusion",
    "text": "Conclusion\nI really enjoyed working on this and learning more about GitHub Actions. This has proved to be a useful tool, though there are a few improvements that could be made:\n\nsome packages update their changelog more frequently than others and so some of the updates I get feel a bit spammy. I could fix this by running my CRON job on a weekly rather than daily schedule.\nI don’t use this as much as I anticipated because some changes are really minor, and I tend to skim them and not pay too much attention. Again, a different CRON frequency could probably help here.\nI’m more interested in some packages than others. {dplyr}, {lubridate}, and {stringr} are the most important, whereas others are just a “nice to have” here. I could separate these out into different jobs, and run them on different schedules.\n\nAnyway, I’d love to hear your thoughts - how do you keep up to date with changes in R packages? Do you have any suggestions for improvements to this workflow? Let me know! Get in touch via Mastodon or LinkedIn."
  },
  {
    "objectID": "posts/r-examples/index.html",
    "href": "posts/r-examples/index.html",
    "title": "R package documentation - what makes a good example?",
    "section": "",
    "text": "I’m currently working on adding to the documentation of the arrow R package, and I’ve started thinking about the qualities of good examples. Specifically, I’m referring to the examples included as part of function documentation. In my experience, the best way for me to achieve rapid familiarity with an R function I haven’t worked with before, or understand how to use a function about which I already understand the basics, is by having example code that I can run. In the book ‘R Packages’, Hadley Wickham remarks that examples are “a very important part of the documentation because many people look at the examples first” and rOpenSci recommend that each of a package’s exported functions should be accompanied by examples.\nIn this blog post, I will explore the things that I believe make for good function examples in documentation, focussing mainly on R."
  },
  {
    "objectID": "posts/r-examples/index.html#what-good-looks-like-in-r",
    "href": "posts/r-examples/index.html#what-good-looks-like-in-r",
    "title": "R package documentation - what makes a good example?",
    "section": "What good looks like in R",
    "text": "What good looks like in R\nI asked people on Twitter for their opinions of good R package documentation in general, and Jonathan Sinclair highlighted the ‘examples’ section from dplyr::case_when, the beginning of which is shown below.\n\n\n\n(image from: https://rdrr.io/cran/dplyr/man/case_when.html)\n\n\nI think Jonathan is spot on in his assessment. To paraphrase, the highlights for him are:\n\nthere is next to no prose or intro\nthere are plenty of comments, as needed, to explain the examples\nthere is a variety of different examples\nthere are examples of what not to do.\n\nThis kind of documentation appeals to my skim-reading self. If I’m trying to accomplish a task, sometimes I just want to run some code and see what happens to get an intuitive feel for what a function does. While I am fully prepared to slow down and read the rest of the documentation, a “quick win” motivates me to invest the additional effort. It tells me that the developers of this code have prioritised making things easy to understand and that the time I am investing will pay off.\nI’ve been skimming through the documentation of some tidyverse and related packages - as I consider many of these to be well documented and easy to read. Here are some things I’ve observed which I think one can do to make function examples look great:\n\ninclude the most basic usage of a function\nuse very simple toy datasets or standard in-built datasets\ndemonstrate non-obvious behaviours of a function\ndemonstrate different parameter values/combinations where relevant\ndemonstrate any unusual parameters\ndemonstrate on different objects if appropriate\nsometimes go beyond the use of an individual function to include common mini-workflows\ngroup documentation and examples for similar functions together\ninclude examples that may lead to unexpected results\ninclude comments to explain examples\nno examples for deprecated functions to discourage their use\nno unpredictable external dependencies - rvest::html_text manually creates HTML to demonstrate capabilities rather than scraping an external site\nsometimes showing the output when it adds to the example (e.g. tidyselect::starts_with() and many other examples from that package)\nexamples should be correct and run without error (unless intended to show erroneous output)"
  },
  {
    "objectID": "posts/r-examples/index.html#what-bad-looks-like-in-r",
    "href": "posts/r-examples/index.html#what-bad-looks-like-in-r",
    "title": "R package documentation - what makes a good example?",
    "section": "What bad looks like in R",
    "text": "What bad looks like in R\nI am not intending to “name and shame” any package authors who haven’t included examples for their functions. It may have been overlooked, there may be plenty of explanation elsewhere, or they may have felt that the code was not sufficiently complex to require examples. It might be true that it seems obvious what a function does, but that makes assumptions about the users of your code that might not hold."
  },
  {
    "objectID": "posts/r-examples/index.html#what-good-looks-like-generally",
    "href": "posts/r-examples/index.html#what-good-looks-like-generally",
    "title": "R package documentation - what makes a good example?",
    "section": "What good looks like generally",
    "text": "What good looks like generally\nWhen reading through examples, one thing that struck me is that when I’m looking at Python docs in Jupyter Notebook (press shift + tab), I also see the output of running the examples.\n\nSimilarly, both examples and outputs are shown in the official docs for some libraries, for example, pandas.\n\nI think this is a helpful feature - less effort is required to see how a function works.\nIn R function documentation, runnable code is often included, but in most cases needs to be manually run by the reader to see the output. I’m torn as to whether this is good or not. On the one hand, it encourages you to run the code and get a more tangible feel for what it does and saves valuable space in the Viewer window in RStudio. On the other hand, it adds an extra manual step to your workflow and lengthens the time until that precious “quick win” of enlightenment when exploring a new function.\nYou get a lot closer to this on the website rdrr.io, which indexes R package documentation and allows examples to be run inline. However, examples are run one after the other without the original code being displayed. So in the case of multiple examples, you have to match up the output to which example it is from.\n\n\n\n(from https://rdrr.io/cran/dplyr/man/case_when.html)\n\n\nSome packages include output as comments within their examples. For instance, the tidyselect package; here’s an example from tidyselect::all_of:\n\n\n\n(from https://rdrr.io/cran/tidyselect/man/all_of.html)\n\n\nAll that said, while the ability to see the output of examples is a nice-to-have, I don’t think it’s essential to good function documentation. With any piece of documentation, it’s necessary to consider the purpose; at a minimum, examples exist to tell the reader how to use a function, and you don’t need to see the output to do that.\nSince I first wrote this, I found out that it is possible to easily run examples from help files by selecting them and then hitting Ctrl+Enter, the same as running code in the Source pane.\n\nAnother thing I wasn’t aware of - pkgdown - commonly used to automatically render docs for packages run examples and displays the output underneath. Check out the example below from the Arrow pkgdown site.\n\nIn conclusion, good examples make functions easier to work with and help readers of your documentation gain a deeper understanding of how a function works. While any examples are better than no examples, you can give your users the best chance of success when using your code with careful thought about the content of your documentation.\nHuge thanks to everyone who responded to my Twitter thread, and to my fantastic colleague Joris Van den Bossche for reading the first draft of this, and our conversations about how things are done in R and Python."
  },
  {
    "objectID": "posts/socialmediagen/index.html",
    "href": "posts/socialmediagen/index.html",
    "title": "Generating social media posts to promote blog posts with {shiny} and {ellmer}",
    "section": "",
    "text": "Writing blog posts is fun, but the next step, getting people to actually read them, can be trickier. I wanted to promote a recent blog post I co-authored for R-Ladies, but coming up with multiple social media posts felt like a bit of a chore.Instead of doing it it manually, I decided to automate the process by building a Shiny app that generates social media content using large language models (LLMs). It was a fun little project, and could even be useful for others too!"
  },
  {
    "objectID": "posts/socialmediagen/index.html#the-solution-a-shiny-app-powered-by-ai",
    "href": "posts/socialmediagen/index.html#the-solution-a-shiny-app-powered-by-ai",
    "title": "Generating social media posts to promote blog posts with {shiny} and {ellmer}",
    "section": "The Solution: A Shiny App Powered by AI",
    "text": "The Solution: A Shiny App Powered by AI\nThe app does the following:\n\nTakes a GitHub Markdown link as input.\nLets users specify hashtags, the number of posts to generate, and whether or not to use emojis.\nAllows selection of tone (e.g., serious, playful, informative).\nCalls Google’s Gemini API via the ellmer package to generate social media posts promotinhg the blog post.\n\n\nWhy ellmer and the Gemini API?\nThe ellmer package was released last year, and is a delightfully straightforward way to directly call LLMs from R. Google’s Gemini API, in particular, offers a generous free tier - up to 15 requests per minute, which was more than enough for my needs."
  },
  {
    "objectID": "posts/socialmediagen/index.html#how-it-works",
    "href": "posts/socialmediagen/index.html#how-it-works",
    "title": "Generating social media posts to promote blog posts with {shiny} and {ellmer}",
    "section": "How It Works",
    "text": "How It Works\nThe app is simple:\n\nEnter the GitHub Markdown file link (or other text source).\nSet your preferences—hashtags, emojis, tone, and how many posts to generate.\nClick generate, and it spits out a bunch of posts.\nCopy and paste into your social media scheduler.\n\nUnder the hood, it builds a prompt using the user’s inputs and calls the Gemini API. The response is formatted into platform-appropriate posts, making it much easier to schedule across different social networks.\n\n\n\nPreview of the app"
  },
  {
    "objectID": "posts/socialmediagen/index.html#deployment-considerations",
    "href": "posts/socialmediagen/index.html#deployment-considerations",
    "title": "Generating social media posts to promote blog posts with {shiny} and {ellmer}",
    "section": "Deployment Considerations",
    "text": "Deployment Considerations\nRight now, the app runs locally, and users need to enter their own Gemini API key as an evironment variable. This prevents abuse of a shared key, but it also makes the app a bit more DIY. I’m considering deploying it on Posit Connect Cloud or a similar service in the future. The trick will be allowing users to bring their own API keys while keeping things secure.\nAnother thought: supporting multiple AI models so users can plug in API keys for different services like OpenAI’s ChatGPT or Anthropic’s Claude."
  },
  {
    "objectID": "posts/socialmediagen/index.html#future-ideas",
    "href": "posts/socialmediagen/index.html#future-ideas",
    "title": "Generating social media posts to promote blog posts with {shiny} and {ellmer}",
    "section": "Future Ideas",
    "text": "Future Ideas\nSome things I’d love to add:\n\nMore refined prompts tailored to different platforms (e.g., longer for LinkedIn, punchier for Bluesky).\nSuggested images to go with posts."
  },
  {
    "objectID": "posts/socialmediagen/index.html#try-it-yourself",
    "href": "posts/socialmediagen/index.html#try-it-yourself",
    "title": "Generating social media posts to promote blog posts with {shiny} and {ellmer}",
    "section": "Try It Yourself!",
    "text": "Try It Yourself!\nWant to give it a go? You can find the repo here: https://github.com/thisisnic/socialmediagen"
  },
  {
    "objectID": "posts/socialmediagen/index.html#wrapping-up",
    "href": "posts/socialmediagen/index.html#wrapping-up",
    "title": "Generating social media posts to promote blog posts with {shiny} and {ellmer}",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThis was a fun little side project that turned out to be actually useful - I’m going to be using it to promote this blog post!\nI’d love to hear if you have any ideas for improvements—hit me up if you try it out!"
  },
  {
    "objectID": "posts/goats/index.html",
    "href": "posts/goats/index.html",
    "title": "Three Goats in a Raincoat",
    "section": "",
    "text": "I am not a fan of the term “imposter syndrome.” It’s a lazy way of ignoring the complex and interconnected, often structural reasons that contribute to many people’s feelings, which manifests itself in a variety of deeply idiosyncratic ways. But I guess the tl;dr is that this is what this post is about.\nI am not someone who has “hobbies” as such; I have interests that I adopt with great enthusiasm, pursue obsessively for a short period of time, often declaring that I have found a lifelong fascination, and then drop once the initial feeling of “endless possibility” has worn off and something else shiny and new finds it way across my path. I suppose my hobby is “pursuing novelty.” The 2022-2023 edition of this came in the form of tabletop role-playing games, and earlier this year, I found myself sitting with some good friends, beers and snacks, working out how my character, “Ach!”, a small goat with a fondness for fainting at inappropriate moments could make their way into a human party undetected.\nThe solution for Ach! and friends was to don a disguise and stand on each others’ shoulders, and this image of 3 goats in a raincoat trying to sneak into a human party perfectly reflects how I feel about myself sometimes as an open source maintainer.\n(Here, I need to get round to commissioning an image of 3 goats in a raincoat standing on each other’s shoulders. The top one has black and red braids and is wearing a hat and fake beard/moustache)\nI am the current maintainer of the arrow R package, which in reality just means I am the person who is listed as such in the package DESCRIPTION file, and have the responsibility of clicking the link in the confirmation email from CRAN when someone submits the latest version of of the package to CRAN. Of course, I do more than just this; I triage bugs, submit patches, review PRs, and occasionally implement new features, but so do other people. While for career-serving purposes, I can technically claim to be “the” maintainer of the package, honestly, I am “a” maintainer and part of a team. This isn’t always reflected in other people’s language, and results in weird moments where people say things to me like, “ah, you wrote arrow!” and I have to respond with, “I absolutely did not, though I did write a lot of the bindings for dplyr::across!”, a topic which subsequently interests me more than it does them."
  },
  {
    "objectID": "posts/goats/index.html#the-tyranny-of-should",
    "href": "posts/goats/index.html#the-tyranny-of-should",
    "title": "Three Goats in a Raincoat",
    "section": "The tyranny of “should”",
    "text": "The tyranny of “should”\nI’ve spent much of this year suffering from the tyranny of “should” regarding my own knowledge and abilities, in a way that has been verging on ridiculous. A lot of it is the perfect storm of adjusting to new responsibility, the deeply unhelpful way in which my self-image when I was younger was built up around being “smart” and “knowing things”, and a knack for punching above my weight by being good at figuring out just enough about a topic to get shit done. I don’t know every single detail of object orientation in R, but I know enough to be able to create new bindings between C++ objects and R6 classes in the arrow R package and expose their methods via fields and active bindings. Despite having looked it up repeatedly over the past few years, I still cannot recall the difference between how things work with static and shared libraries, but I did manage to fix a bug requiring me to bump the version of the C++ date library that Arrow vendors, via inspecting old pull requests and helpful feedback I received on the PR I submitted.\nIt came to a head at this year’s posit::conf, where I had the privilege of co-teaching a workshop about Arrow with the wonderful Stephanie Hazlitt. We spent months preparing materials and practicing teaching to our laptop screens, but when the event itself rolled around, teaching it to a room just shy of 60 people was a different experience entirely. It was intimidating being in front of a room of eager learners, and any jokey asides I was usually capable of making went out of the window, and I just taught the materials fairly plainly, stumbling over my words a bit, and finding the moments of silence in the room as I was teaching pretty awful. Subsequent feedback from folks I trust enough to deliver at least some honesty alongside their validation has led me to conclude that the only person who really noticed or cared about this was me. I was doing my old trick of snatching defeat from the jaws of victory, and realised later that my self-expectations were totally unreasonable. While I used to be able to absolutely smash through delivering a well-practiced 2-day “introduction to R” course, and delighted in engaging the folks in the room and showing them what they (and R!) were capable of, it’s 5 years since I last did that on the regular. This was the first time these materials had seen the light of day, and at no less than posit::conf, daunting enough on its own. And honestly, this is all ego. We ran a good workshop, people were engaged, and we wrote some quality reusable materials. Yes, there’s room for improvement, but overall it was solid. Delivery of content is something I can (and will) work on. I’ve applied for The Carpentries instructor training, and have plans to get back into the swing of teaching by running workshops (on Arrow and other topics) at user events."
  },
  {
    "objectID": "posts/goats/index.html#the-power-of-i-dont-know-but-i-can-find-out",
    "href": "posts/goats/index.html#the-power-of-i-dont-know-but-i-can-find-out",
    "title": "Three Goats in a Raincoat",
    "section": "The power of “I don’t know but I can find out”",
    "text": "The power of “I don’t know but I can find out”\nThe second day of posit::conf was spent being a teaching assistant for the fantastic Andy Teucher, who was teaching “Fundamentals of Package Development”. I managed to escape a lot of this “should” nonsense here, so when one of the course attendees asked me about where to store CSV files to use in unit tests, I happily admitted I wasn’t sure but could find out, and together we had a look in “Writing R Packages”, where I couldn’t find the information, and then suggested the approach I usually take when working on arrow - look at what folks who often define best practices do in the packages that they maintain. We took a look at readr, found the files in the testthat directory, and concluded that unless there’s reason to want to do anything more complicated (like make those datasets available to end users), then that approach is fine. Not knowing the answer instantly wasn’t a hindrance to working out the necessary solution. Learning how to say “I don’t know, but let’s find out together” is one of the most important things I learned when I was first teaching people how to use R. A teacher doesn’t have to know everything, but should be able to help a learner find the information they need."
  },
  {
    "objectID": "posts/goats/index.html#the-power-of-community",
    "href": "posts/goats/index.html#the-power-of-community",
    "title": "Three Goats in a Raincoat",
    "section": "The power of community",
    "text": "The power of community\nThe rest of the conference week was pretty awesome. I was in the middle of a CRAN resubmission (well, actually a re-re-resubmission, but let’s not go there) which had got a bit hairy, and I needed some help tracking down the source of the bug. I spent some time briefly engaging in a bit of pair programming with Jonathan Keane and Neal Richardson, who’ve both been involved with Arrow for a lot longer than me, and I’m always taken aback by just how quickly they both get to the source of a problem any time I ask for help. Part of my “knowledge anxiety” manifests as me sometimes taking longer than I would like to process things when communicating verbally about technical topics, which leads to me getting really frustrated when I’m just not “getting” things in the moment that I know later will seem pretty obvious and uncomplicated. This happened when we were looking at the arrow bug, but I had this sudden moment of clarity upon realising…nobody cared except me. Jon and Neal are great collaborators and are always happy to explain things again if there’s time, and aren’t going to judge me for it.\nI also realised that there is no universal measure of what I should know or where I should be at. While I always want to know more about how things work, I don’t have to know everything and it’s a pretty unrealistic expectation for me to have of myself; sure I can (and often do!) go read a whole load of the codebase and related concepts, but that’ll never be the same as also leaning on other people’s years of experience and knowledge. The whole point of being part of a community is to be able to share both overlapping and divergent knowledge."
  },
  {
    "objectID": "posts/goats/index.html#progress-is-power",
    "href": "posts/goats/index.html#progress-is-power",
    "title": "Three Goats in a Raincoat",
    "section": "Progress is power",
    "text": "Progress is power\nI don’t think there is a universal solution to this problem of feeling like you “should” know more, but all I know is what has worked for me. Public work is important - social media, blog posts, talks, workshops, whatever. It can be scaled to wherever you’re at. There’s always something you’ll be surprised that you know but others don’t. And it creates a lovely feedback loop whereby a little bit of external validation can go a long way.\nLearning is also important - I did the first half of the Udacity C++ Nanodegree this year, and while a lot of what it taught me was that I never want to be a full-blown C++ developer (I’d rather make weird buildings and spaceships out of existing Lego pieces than become a polymer scientist just to create custom bricks), realising that I could learn C++ at that level if I really wanted to, was invaluable. Part of the course involved getting acquainted with cmake, and whilst I can’t claim expertise there, dabbling in a bit of the whats and whys helped make many related Arrow project issues seem less mystical.\nReassurance and validation are good and well, but in my experience, having tangible proof of the things that I do know is more effective."
  },
  {
    "objectID": "posts/goats/index.html#fake-it-til-you-make-it-is-deeply-problematic",
    "href": "posts/goats/index.html#fake-it-til-you-make-it-is-deeply-problematic",
    "title": "Three Goats in a Raincoat",
    "section": "“Fake it til you make it” is deeply problematic",
    "text": "“Fake it til you make it” is deeply problematic\nThe commonly received advice is “fake it ’til you make it”. Pretend you feel like you belong and are confident, until that becomes the case. I’ve spent a long time attempting this, and the problem is that it doesn’t actually work, because it doesn’t address the underlying issue. It’s only since I started to own the fact that I don’t feel comfortable in every environment or domain and working out what I need to do to feel more comfortable that I’ve felt my confidence growing.\nIn the past month, I’ve been a lot more open about how I’ve been feeling around this. It’s been tricky as I’ve been scared that my vulnerability just looks weakness that I shouldn’t show around other people, or just come off as moaning, but it’s had massive benefits. During the first couple of days of posit::conf this year, I suffered the worst ongoing anxiety I’ve had all year - I had a constant knot in my chest - but despite that managed to have a good time as everyone was very accepting. I can say without a doubt that pretending to be fine would have made things infinitely worse.\nThere was another point during the conference when I casually mentioning that I was feeling quite hopeful about a potential opportunity but not entirely sure if it was in the bag, as I suspected I might be up against someone whose background I find impressive. It was kindly pointed out to me that each of us bring different things to the table, a comment which has since set off a chain reaction of me starting to appreciate what I can do rather than what I can’t."
  },
  {
    "objectID": "posts/goats/index.html#the-cure-for-imposter-syndrome",
    "href": "posts/goats/index.html#the-cure-for-imposter-syndrome",
    "title": "Three Goats in a Raincoat",
    "section": "The cure for imposter syndrome",
    "text": "The cure for imposter syndrome\nThe most important thing I learned this year is that the cure for imposter syndrome isn’t persuading yourself that you aren’t just 3 goats in a raincoat pretending to be a person, but instead surrounding yourself with folks who wouldn’t really care if you were anyway because goats are cool and that’s a pretty awesome feat of acrobatics and balancing."
  },
  {
    "objectID": "posts/c_deepr/index.html",
    "href": "posts/c_deepr/index.html",
    "title": "Explaining the C bits at the start of ‘Deep R Programming Ch14: Interfacing compiled code’",
    "section": "",
    "text": "One of my goals for next year is to get a deeper understanding of R’s C API. I’m making a start on this by reading Chapter 14 of Deep R Programming by Marek Gagolewski: “Interfacing compiled code”. It’s a great resource, though the chapter preface states “we assume basic knowledge of the C language”. I do not have this knowledge My C knowledge is fairly limited, and so this blog post will pull out some of the details from that chapter, especially bits where I’ve had to go “wtf is that?!” or remind myself by googling. My current level of C knowledge at the moment is pretty minimal; the main things I know are:\n\nC is a compiled language (as opposed to an interpreted language) and C code needs compiling before it can be run\nA lot of R’s internals are based on C\nC is a statically-type language; this means that variable types are defined when the variable is created and cannot later change other than via explicit manual casting\n\nAnd that’s basically it! I imagine there are other bits I don’t realise I know which I’ve picked up from being an R package maintainer and dabbling in a few C++ tutorials, but I’ll try to explain everything as much as possible. OK, let’s do this!\nThe book chapter provides an example package with a simple C function implemented, and walks us through the code step-by-step. Great!\nSection 14.1.1 starts off with an example of a C function defined in src/cfunc.h. I guess the first thing to note is the location of the file - in the package’s src directory. This is where any compiled code needs to go, typically C or C++ code, or even Fortran if you’re really going old-school.\n\nHeader files and source files\nAnother thing to note here is the file name, which ends in .h. C code can be divided into header files (ending in .h) and source files (ending in .c). Header files contain the function declarations (including variable types) and other things like macros (named bits of code for the pre-processor to work with). They’re sometimes referred to as the interface - they contain information about functions’ inputs and outputs - including the argument names and types.\n\n\nOnce-only includes\nThe first couple of lines of code in the header file contain these lines:\n#ifndef __CFUNS_H\n#define __CFUNS_H\nand the final line is\n#endif\nWhat’s happening here is that, often we can end up with projects containing multiple files, some of which source each other, and include them. We don’t want to end up with duplication of the headers which have been included, otherwise the compiler will raise an error, so we put them in an #ifndef wrapper, and give them a name. Basically, what we’re saying to the preprocessor here is that if this name hasn’t already been defined, defined it and include this code, but if it’s already defined then skip this.\n\n\nIncludes\nThe third line in src/cfunc.h is:\n#include &lt;stddef.h&gt;\nThis allows for the inclusion of a file from the C standard library, which has a few different variables included. The key one for us here is size_t, which is commonly used for iterating over items in arrays - we need this as we’ll be including a for loop in the definition of our function.\n\n\nThe preprocessor\nAbove I casually mentioned the C preprocessor a couple of times without defining it. A succinct and perhaps naive summary is that there are multiple steps in the compilation of C code. One of these phases is preprocessing and it involves things like processing any additional files we’ve said we wanted to include, and replacing macros with their definitions.\n\n\nDeclarations\nSo, the declaration for the function in the example looks like this\ndouble my_c_sum(const double* x, size_t n);\nIn words, this means that:\n\nit is a function which returns an object of type double\nthe function name is my_c_sum\nthe first argument is called x\nx is a pointer to a variable of type double\nx is a const variable, which means it won’t be modified in the body of the function\nthe second argument is called n\nn is of type size_t\n\nThis concept of a pointer just means that x contains the memory address of the double that we pass in, rather than a copy of the values in it. This prevents us from copying the values unnecessarily.\n\n\nSource file\nSource files contain the body of the function, sometimes called the implementation.\nThe code in the book chapter goes on to show the content of the file src/cfuncs.c. The first line of this file is:\n#include \"cfuns.h\"\nThis is including the header file we discussed above. The rest of the code in the source file contains the definition of my_c_sum:\n/* computes the sum of all elements in an array x of size n */\ndouble my_c_sum(const double* x, size_t n)\n{\n    double s = 0.0;\n    for (size_t i = 0; i &lt; n; ++i) {\n        /* this code does not treat potential missing values specially\n           (they are kinds of NaNs); to fix this, add:\n        if (ISNA(x[i])) return NA_REAL;  // #include &lt;R.h&gt;  */\n        s += x[i];\n    }\n    return s;\n}\nThe function signature here is identical to how it is defined in the header file. The for loop uses the n argument which was passed in to represent the size of the array to loop through. In numerous other languages we’d calculate the size of the array in the body of the function, but in C you cannot have an array of unknown size, and so it must be passed in as a parameter. I think this is to do with how the C compiler allocates memory; more modern C does have the concept of variable-length arrays.\nThe chapter goes on to discuss further examples which then show how to include a wrapper which can be called by R. I won’t discuss this here, as the text there is all explained well, and the contents are more specific to R’s C API, and not specifically just C-related topics.\nHere’s a summary of the C-related topics mentioned here:\n\nheader files and source files\nincludes\nonce-only includes\nthe preprocessor\nvariable-length arrays\nconst variables\npointers\nstatically-typed languages\ncompiled and interpreted languages"
  },
  {
    "objectID": "posts/rc/index.html",
    "href": "posts/rc/index.html",
    "title": "Recurse Center Return Statement",
    "section": "",
    "text": "I spent 3 months earlier this year at Recurse Center in New York. Here’s a summary of the highlights of my time there!"
  },
  {
    "objectID": "posts/rc/index.html#what-is-recurse-center",
    "href": "posts/rc/index.html#what-is-recurse-center",
    "title": "Recurse Center Return Statement",
    "section": "What is Recurse Center?",
    "text": "What is Recurse Center?\nThe simplest explanation of what Recurse Center is is that it’s like a writer’s retreat but for programmers. Participants have to apply to get in, and there are 3 stages. The first is a written application, followed by a conversational interview, and then a pair programming interview. Generally, the intention is to assess whether you’ll be a good fit for RC. The selection criteria are stated explicitly on the website, but to summarise, they’re looking for self-motivated people who enjoy programming and are pleasant to be around. It’s not about being an amazing programmer; though I met some people with seriously impressive skills there, I also met newer programmers who were enthusiastic and engaged.\nRC can be attended remotely online or in person, but I opted for the in-person experience to get the most out of it. The hub, the in-person location is in Brooklyn, and takes up 2 floors of an office building. The 4th floor is the main floor where people code, socialise, do pair programming, and hang out in the kitchen, presentation space, or the meeting rooms. The 5th floor is the quiet floor where people can do more focused work without interruption.\nRC has a code of conduct, as well as 4 more general social rules:\n\nNo well-actually’s\nNo feigned surprise\nNo backseat driving\nNo subtle -isms\n\n\n\n\nA printed poster of RC’s social rules\n\n\nAs well as social rules about what not to do, there are 3 guiding principles, or self-directives, about what to do:\n\nWork at the edge of your abilities\nBuild your volitional muscles\nLearn generously\n\nThese explicit expectations lead to a fantastic learning environment where some of the more toxic elements that can sometimes be found in tech were avoided, and folks worked on project that really mattered to them and helped other people do the same.\nRecurse Center is a business, and makes its money from recruitment - RC works with partner companies looking for software engineers and similar roles, though admission to RC isn’t predicated on looking for employment via them, and is never pushed on people."
  },
  {
    "objectID": "posts/rc/index.html#why-did-i-go",
    "href": "posts/rc/index.html#why-did-i-go",
    "title": "Recurse Center Return Statement",
    "section": "Why did I go?",
    "text": "Why did I go?\nWhen I decided to go to RC, I was at the beginning of a career break. I had done some consultancy/contract work early on, but had decided that I needed a proper pause. I had begun working on the book on Arrow that I’m co-authoring, and splitting my attention between the two things wasn’t working well for me. I also wanted some focused learning time - I had a ton of side projects I’d been meaning to work on but had never gotten moving and I felt like this would be a great opportunity to push them forwards.\nMy secondary motivation was how I was feeling at the time. I was lacking confidence in some of my technical skills, and know from experience that the best way to tackle that is learn new things and get things done, to disprove some of the insecurities I was having.\n\n\n\nA cross-stitched piece on the wall at RC with the text “be gay find primes”"
  },
  {
    "objectID": "posts/rc/index.html#what-did-i-intend-to-work-on",
    "href": "posts/rc/index.html#what-did-i-intend-to-work-on",
    "title": "Recurse Center Return Statement",
    "section": "What did I intend to work on?",
    "text": "What did I intend to work on?\nBefore I went to RC, I had a huge list of potential things to work on. I didn’t plan on doing all of these, but this was my initial brain dump of everything I thought might be useful or interesting in future:\n\nRead “Writing R Extensions”\nDo the course Nand2Tetris to get a better foundation of “lower level stuff”\nLearn C\nLearn more about the finer details of how building R packages work\ncontribute to parsermd so it works for Quarto markdown documents\nfinish the Udacity C++ nanodegree I’d done some of a while ago\nlearn more about the C++ build process\nDo all of the C sessions of CS50\nDo some work on the Arrow book\n\n\n\n\nSome of the retro machines at the RC hub."
  },
  {
    "objectID": "posts/rc/index.html#what-did-i-actually-work-on",
    "href": "posts/rc/index.html#what-did-i-actually-work-on",
    "title": "Recurse Center Return Statement",
    "section": "What did I actually work on?",
    "text": "What did I actually work on?\nOne of the principles of RC is to use your volitional muscles and work on what interests you rather than things you think you “should” work on. There’s a balance to be struck here, but there was a great exercise early on where we were guided through questions to ask ourselves to work out what was going to be the best things to focus on.\nIn the end, I didn’t get through all of the things on my original list, but had a much more exciting time doing the following things:\n\nwent through most of Nand2Tetris\nplayed around with compilation and decompilation and how compiler flags change the code produced\nplayed with assembly code\nstarting going through the book Crafting Interpreters and plan to do more another time!\nspent lots of time pairing with other people on my and other people’s code and developing a love for pair programming\ndid a few presentations on Nand2Tetris and why it’s such a great course!\nwrote an R-based Quarto markdown parser which implements recursive descent parsing\ndelved into the Quarto codebase and developed a new version of the parser which takes advantage of pandoc instead of doing everything the hard way\n\nAnd alongside this:\n\ndid a ton of writing of the Arrow book I’m co-authoring\nfinished off interviewing for a job I’d applied for at Novartis which I’m super excited to start tomorrow!\nattended 2 days of Carpentries instructor training\nhad regular lessons with a public speaking tutor\nsubmitted and got accepted to co-present a talk to posit::conf\nhanded over arrow maintainership to the fantastic Jon Keane"
  },
  {
    "objectID": "posts/rc/index.html#what-did-i-learn",
    "href": "posts/rc/index.html#what-did-i-learn",
    "title": "Recurse Center Return Statement",
    "section": "What did I learn?",
    "text": "What did I learn?\n\nlow-level programming concepts felt out of reach for a long time; most docs are aimed at people who already understand the tech being described, there’s a lot of foundational computer science knowledge that is assumed that I didn’t have, and it’s hard to know where to find good learning resources. However, I learned that actually, it isn’t nearly as out of reach as I’d thought and all I really need is to find that one good resource, and have time to explore it. Nand2Tetris is an awesome course!\na solid community of peers is invaluable. I’ve been lucky enough in my career so far to mostly have either a community of peers or excellent mentors, but in future I’m going to aim to make sure I have both, whether that’s via a job role or engaging with wider programming communities more fully.\npair programming is a wonderful thing and is massively underutilised. Pairing shouldn’t only be utilised when there’s a bug, but be a regular practice. It helps share assumptions and norms,\nworking on the things I want to as well as the things I think I should work on is so key to productivity\nto listen to my gut when it comes to my own learning. I have had a frustration for years with public speaking where I know I’m not terrible at it, want to be better, but asking friends and colleagues for feedback often led to (lovely, kind, well-meaning) validation but not the actionable feedback I wanted. Working with a tutor has been amazing for helping me identify my strengths (I convey passion and excitement for my topic, and especially when I teach, really try to connect with my audience) and weaknesses (my natural speaking speed is about 3 times what it should be, and I could work on structuring information better within a talk)\nnot to mistake being limited for time to work on a problem with not being able to solve the problem\n\n\n\n\nSome craft projects which were on display at RC"
  },
  {
    "objectID": "posts/rc/index.html#conclusion",
    "href": "posts/rc/index.html#conclusion",
    "title": "Recurse Center Return Statement",
    "section": "Conclusion",
    "text": "Conclusion\nI can honestly describe the 3 months I spent at Recurse Center as the best solid 3 month period of my life. I learned a huge amount about, not only programming, but my own motivation. I made some amazing friends - my fellow RC participants and the faculty there are some of the coolest people I’ve ever met - and will be staying involved in the community in the longer term."
  }
]