---
title: "AI Tooling and Open Source"
author: "Nic Crane"
date: "2026-01-27"
categories: [AI]
image: "ai_code_future.png"
toc: true
toc-depth: 2
---

![](ai_code_future.png){width=400 fig-align="center"}

Working on Arrow, I've been noticing an increase in AI-generated pull requests recently. In this blog post, I discuss my take on how AI tooling affects open source, the actions maintainers have been taking to address the less positive aspects, and emerging policies that open source projects are implementing around the topic of AI-generated pull requests.

## Attitudes to AI tools - licensing and slop

Earlier reactions to the use of these AI tools in some open source projects have been quite negative, and there are lots of examples of open source projects explicitly banning the use of AI tools in generating contributions, for example, [Gentoo Linux in 2024 banned all AI contributions](https://www.theregister.com/2024/04/16/gentoo_linux_ai_ban/).

I certainly have sympathy for this perspective, and there are certainly good and valid reasons around complications relating to licensing and AI-generated code that I believe open source developers need to be cautious of. The ASF have published some [high-level guidelines](https://www.apache.org/legal/generative-tooling.html) on the use of generative tooling that capture the risk of replicating copyrighted materials.

That said though, I also believe that the evolution of these tools means that condemning them outright is throwing the baby out with the bathwater. Entire features created with AI absolutely can be problematic from a licensing perspective, but much maintenance work of existing codebases is less fraught. In my experience, fixes and changes generated based on the existing codebase and reasoning around it rarely end up replicating other codebases, and these tools are a net win for maintainers when used well.

As the sophistication of tools has increased, I found that at some point in 2025, the balance tipped for me from relatively poor results towards them becoming net useful. I also believe a lot of developers are in this place where many people are using these tools but fewer are openly admitting it. While there are negative opinions about these kinds of tools, I think it's unrealistic to pretend that they aren't being used prevalently.

## The problem of AI-generated PRs in open source

There is a certain class of AI-generated pull request that is becoming problematic. The pattern is often obvious - a pull request is submitted by a contributor who has never previously contributed to the codebase. The code may have clear signs of AI tool usage - verbose and unnecessary comments, overly broad scope of changes, excessive or non-existent unit tests, and changes which span multiple areas of the codebase which human contributors don't tend to have expertise on.

A charitable interpretation of these PRs is that they represent a genuine but misguided desire to be helpful. A less charitable interpretation suggests that the author wants to claim an open source contribution, without any real understanding of the code that they're changing, or interest in iterating on a long-running pull request until it's ready to merge.

To a certain extent I get it. Some of my first open source pull requests were absolutely done for the sake of something that I viewed as a real achievement and not a genuine investment in a codebase, simply because I didn't really understand how any of it worked at that point. And so, I don't want to outright condemn people with this mindset.

And I've made a fair share of embarrassing mistakes in my own use of AI tools. In my earlier explorations, I accidentally allowed Claude to push to an upstream branch instead of my own fork, and proposed poorly thought-through changes that I did not understand well enough to take responsibility for when maintainers responded with thoughtful questions. The realisation of this potential for harm made me drastically alter my approach, but I share this openly to acknowledge the need to empathise with novice users of complex tools.

All of that said though, as an open source maintainer, I have limited time to dedicate to code review. I love working with new contributors, both for the human connection and because it improves project health by increasing the number of people who are able to contribute. However, there is very little intrinsic value in me reviewing AI-generated code which the author has either abandoned or will just continue to use AI to respond to my suggestions. At this point I may as well just use AI myself to make this pull request.

Thoughtful use of AI tools requires multiple iterations and changes, and questioning of the tooling as to the reasoning behind changes, and taking ownership of the changes through the understanding gained during the process. I believe this is a net positive and it would be hypocritical to condemn others doing this.

The distinction here that is important to me is the difference between thoughtful uses of these tools to augment genuine work versus a sort of "throw it over the fence and hope it gets merged" approach.

## Taking it to the mailing list

Given all the negativity I've seen online around the use of AI tooling, I was both nervous and curious to see what the conversation would look like when I opened the discussion on the Apache Arrow developer mailing list around the use of these tools. It was great to see that, as ever, the Apache Arrow developer community engaged in a thoughtful discussion in which folks suggested additions to my suggested phrasing of policy, and chimed in with their own experiences. This clearly isn't a novel or new idea as Andrew Lamb pointed me straight to some [excellent guidelines in the DataFusion project](https://datafusion.apache.org/contributor-guide/index.html#ai-assisted-contributions). (For context, DataFusion is a query engine built on Arrow, used to be kept in the former Arrow monorepo, and is part of the Arrow community). DataFusion had already developed and published some excellent guidelines which I borrowed some ideas from as well. Since I opened [the Arrow pull request](https://github.com/apache/arrow/pull/48952), I saw other projects also making similar decisions and our own pull request being linked to in those.

I decided to give the pull request a few extra days for people to add extra opinions before merging, but it will be interesting to see what happens now. I also recognise that we actually can't necessarily tell when people make thoughtful use of AI tooling, and my own personal motivation for writing this guidance was that I can link to it when reviewing pull requests in which I suspect more engagement is needed from the submitter. I've seen these both myself and from other people, and it takes a large amount of emotional energy trying to respond to something with the empathy and welcoming nature that we wish to show towards new contributors, while not investing time and energy in a pull request which may well be abandoned if the submitter isn't interested in doing any extra work. Conversely though, if they are interested, we don't want to drive them away.

I see many other projects are also considering these issues at the moment as well, for example [Jupyter](https://github.com/jupyter/governance/issues/326). A refreshingly realistic perspective was adopted recently by the [Journal of Open Source Software](https://blog.joss.theoj.org/2026/01/preparing-joss-for-a-generative-ai-future) who adapted their review process given the increase in AI tooling, placing more emphasis on the uniquely human factors crucial for creating quality software.

## Other challenges

Pull requests aren't the only challenge that open source is seeing in terms of AI tool usage. Another issue that multiple projects have also seen recently is an uptick in security reports. These appear to constitute things that would be considered bugs or edge cases, and deploying fixes may genuinely improve the codebase, but it makes it easy to question the intention of the submitter, given that the status as security holes is tenuous at best. As with pull requests, I don't want to completely condemn this approach, because I believe that finding and fixing true security issues can only be a net positive for open source projects, but this approach of what appears to be clever phrasing to paint minor bugs as security incidents is at best disingenuous.

This is becoming more prevalent, as shown by the [curl project recently closing its bug bounty program](https://daniel.haxx.se/blog/2026/01/26/the-end-of-the-curl-bug-bounty), and similar issues [experienced by Apache Log4j](https://daniel.haxx.se/blog/2026/01/26/the-end-of-the-curl-bug-bounty/comment-page-1/#comment-27393).

The irony of the spurious reporting of alleged potential Denial-of-Service attacks is delightfully captured by curl author Daniel Stenberg in the abstract of his [upcoming FOSDEM talk](https://fosdem.org/2026/schedule/event/B7YKQ7-oss-in-spite-of-ai/) which refers to "Sloppy humans causing Denial-of-Service attacks by overloading maintainers with quickly produced almost-real-looking rubbish".

AI tooling is having a significant effect on open source development and it's fascinating to see it play out in real time. I hope it will be a net positive, but there are certainly challenges ahead, and it's exciting to see how fast things are moving right now.
