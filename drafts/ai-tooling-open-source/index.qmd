---
title: "AI Tooling and Open Source"
author: "Nic Crane"
date: "2026-01-27"
categories: [AI]
image: "ai_code_future.png"
toc: true
toc-depth: 2
---

![](ai_code_future.png){width=400 fig-align="center"}

As one of the maintainers of Apache Arrow, lately I've been noticing an increase in AI-generated pull requests. In this blog post, I discuss how AI tooling affects open source, the actions maintainers have been taking to address the less positive aspects, and emerging policies that open source projects are implementing around the topic of AI-generated pull requests.

## Attitudes to AI tools - licensing and slop

Earlier reactions to the use of AI tools in some open source projects have been quite negative, and there are lots of examples of open source projects explicitly banning the use of AI tools in generating contributions, for example, [Gentoo Linux in 2024 banned all AI contributions](https://www.theregister.com/2024/04/16/gentoo_linux_ai_ban/).

I have some sympathy for this perspective, and there are certainly good and valid reasons around complications relating to licensing and AI-generated code that I believe open source developers need to be cautious of. The ASF have published some [high-level guidelines](https://www.apache.org/legal/generative-tooling.html) on the use of generative tooling that capture the risk of replicating copyrighted materials.

That said though, I also believe that the evolution of these tools means that condemning them outright is throwing the baby out with the bathwater. Entire features created with AI absolutely can be problematic from a licensing perspective, but much maintenance work of existing codebases is less fraught. In my experience, fixes and changes generated based on the existing codebase and reasoning around it rarely end up replicating other codebases, and these tools are a net win for maintainers when used well.

As the sophistication of tools has increased, I found that at some point in 2025, the balance tipped for me from relatively poor results towards them becoming net useful. I also believe a lot of developers are in this place where many people are using these tools but fewer are openly admitting it. While there are negative opinions about these kinds of tools, I think it's unrealistic to pretend that they aren't being used pretty widely.

## The problem of AI-generated PRs in open source

There is a certain class of AI-generated pull request that is becoming problematic. There is often a pattern to them - a pull request is submitted by a contributor who has never previously contributed to the codebase. The code may have clear signs of AI tool usage - verbose and unnecessary comments, overly broad scope of changes, excessive or non-existent unit tests, and changes which span multiple areas of the codebase which human contributors don't tend to have expertise on simultaneously.

To a certain extent I get it. Some of my first open source pull requests were absolutely done for the sake of something that I viewed as a real achievement and not a genuine investment in a codebase, simply because I didn't really understand how any of it worked at that point.  And I've made a fair share of embarrassing mistakes in my own use of AI tools. In my earlier explorations, I accidentally allowed Claude to push to an upstream branch instead of my own fork, and proposed poorly thought-through changes that I did not understand well enough to take responsibility for when maintainers responded with thoughtful questions. The realisation of this potential for harm made me drastically alter my approach.

All of that said though, most open source maintainers are pressed for time to work on the project.  It's great working with new contributors, both for the human connection and because it improves project health by increasing the number of people who are able to contribute, but there is very little value in a maintainer reviewing AI-generated code which the author has either abandoned or will just continue to use AI to respond to the provided suggestions.

Thoughtful use of AI tools requires multiple iterations and changes, and questioning of the tooling as to the reasoning behind changes, and taking ownership of the changes through the understanding gained during the process.

## Taking it to the mailing list

After noticing the increase in AI generated PRs and wanting to validate my approach to handling them with the wider community, I started a discussion on the Arrow developer mailing list about defining a set of community-agreed guidelines for AI-generated PRs.

In reality, we can't necessarily tell when people make thoughtful use of AI tooling, and so my own personal motivation for suggesting this guidance was that I can drop in a link to it during reviews of PRs when I suspect more engagement is needed from the potential contributor before it's ready to merge. 

It's hard to know what to say, and takes a chunk of emotional energy trying to respond to something with the empathy and welcoming nature that we want to show towards new contributors, while simultaneously not investing too much time and energy in a pull request which may well be abandoned. Conversely though, if the contributor really is interested in engaging, we don't want to drive them away.

Given all the negativity I've seen online around the use of AI tooling, I was both nervous and curious to see what the conversation would look like when I opened the discussion on the Apache Arrow developer mailing list around the use of these tools. 

It was great to see that, as ever, the Apache Arrow developer community engaged in a thoughtful discussion in which folks suggested additions to my suggested phrasing of policy, and chimed in with their own experiences. This clearly isn't a novel or new idea, and Andrew Lamb pointed me straight to some [excellent guidelines which already existed in the DataFusion project](https://datafusion.apache.org/contributor-guide/index.html#ai-assisted-contributions). (For context, DataFusion is a query engine built on Arrow, used to be kept in the former Arrow monorepo, and is part of the Arrow community). I borrowed some ideas from the DataFusion guidelines as well as the contributions from other folks on the mailing list.  The key recommendations we ended up with were:

> * Only submit a PR if you are able to debug and own the changes yourself - review all generated code to understand every detail
> * Match the style and conventions used in the rest of the codebase, including PR titles and descriptions
> * Be upfront about AI usage and summarise what was AI-generated
> * If there are parts you don't fully understand, leave comments on your own PR explaining what steps you took to verify correctness
> * Watch for AI's tendency to generate overly verbose comments, unnecessary test cases, and incorrect fixes
> * Break down large PRs into smaller ones to make review easier

Since we had this discussion, the [PR](https://github.com/apache/arrow/pull/48952) was linked to by a couple of other projects and through following the collated examples, I noticed even more open source projects which had already had similar discussions or recent policy updates, for example, [Jupyter](https://github.com/jupyter/governance/issues/326), [Zulip](https://github.com/zulip/zulip/blob/main/CONTRIBUTING.md#ai-use-policy-and-guidelines), [LLVM](https://llvm.org/docs/AIToolPolicy.html), and [Python](https://devguide.python.org/getting-started/generative-ai/). 

## Other challenges

Pull requests aren't the only challenge that open source is seeing in terms of AI tool usage; multiple projects have also recently experienced an uptick in security reports. Some of these appear to constitute things that would be considered bugs or edge cases, and deploying fixes may genuinely improve the codebase, but some examples I've seen appear to include strategic phrasing to paint bugs as security incidents, and feel a little disingenuous.

This is becoming more prevalent, as shown by the [curl project recently closing its bug bounty program](https://daniel.haxx.se/blog/2026/01/26/the-end-of-the-curl-bug-bounty), and similar issues [experienced by Apache Log4j](https://daniel.haxx.se/blog/2026/01/26/the-end-of-the-curl-bug-bounty/comment-page-1/#comment-27393).

The irony of the spurious reporting of alleged potential Denial-of-Service attacks is delightfully captured by curl author Daniel Stenberg in the abstract of his [upcoming FOSDEM talk](https://fosdem.org/2026/schedule/event/B7YKQ7-oss-in-spite-of-ai/):

> "Sloppy humans causing Denial-of-Service attacks by overloading maintainers with quickly produced almost-real-looking rubbish".

AI tooling is having a significant effect on open source development and it's fascinating to see it play out in real time. I hope it will be a net positive, but there are certainly challenges ahead, and it's exciting to see how fast things are moving right now.
