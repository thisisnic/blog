---
title: "User-defined functions in arrow"
author: "Nic Crane"
date: "2021-05-18"
categories: [R]
image: "arrow_examples.png"
---

```{r}
#| warning: false
#| message: false
library(arrow)
library(dplyr)

register_scalar_function(
  name = "add_one",
  function(context, trip_distance) {
    trip_distance + 1
  },
  in_type = schema(
    trip_distance = float64()
  ),
  out_type = float64(),
  auto_convert = TRUE
)
```

```{r}
#| cache: true
results <- bench::mark(
  compute = open_dataset("~/data/nyc-taxi") |>
    filter(year == 2019, month == 9) |>
    transmute(x = trip_distance + 1) |>
    collect(),
  udf = open_dataset("~/data/nyc-taxi") |>
    filter(year == 2019, month == 9) |>
    transmute(x = add_one(trip_distance)) |>
    collect(),
  iterations = 10,
  check = FALSE
)
```

```{r}
results
```
The time it took when using Arrow's in-built compute function was about hald the time it took using a UDF.  Crucially, there was significantly more memory allocated by R when using the UDF, as well as more garbage collections performed, which leads me to conclude that the UDF is being run after the results have been pulled back into R.



